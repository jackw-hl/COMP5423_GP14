{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 67673,
     "status": "ok",
     "timestamp": 1764030872513,
     "user": {
      "displayName": "谭黄骜",
      "userId": "15367769941446326953"
     },
     "user_tz": -480
    },
    "id": "95727d60",
    "outputId": "374e2a3a-f09f-4fcb-e09e-d335e5bbcc90"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ragatouille\n",
      "  Downloading ragatouille-0.0.9.post2-py3-none-any.whl.metadata (28 kB)\n",
      "Collecting llama-index (from ragatouille)\n",
      "  Downloading llama_index-0.14.8-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting faiss-cpu (from ragatouille)\n",
      "  Downloading faiss_cpu-1.13.0-cp39-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (7.7 kB)\n",
      "Requirement already satisfied: langchain_core in /usr/local/lib/python3.12/dist-packages (from ragatouille) (0.3.78)\n",
      "Collecting colbert-ai>=0.2.19 (from ragatouille)\n",
      "  Downloading colbert_ai-0.2.22-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (from ragatouille) (0.3.27)\n",
      "Collecting onnx (from ragatouille)\n",
      "  Downloading onnx-1.19.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: srsly in /usr/local/lib/python3.12/dist-packages (from ragatouille) (2.5.1)\n",
      "Collecting voyager (from ragatouille)\n",
      "  Downloading voyager-2.1.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.9 kB)\n",
      "Requirement already satisfied: torch>=1.13 in /usr/local/lib/python3.12/dist-packages (from ragatouille) (2.8.0+cu126)\n",
      "Collecting fast-pytorch-kmeans (from ragatouille)\n",
      "  Downloading fast_pytorch_kmeans-0.2.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (from ragatouille) (5.1.1)\n",
      "Collecting bitarray (from colbert-ai>=0.2.19->ragatouille)\n",
      "  Downloading bitarray-3.8.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (34 kB)\n",
      "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (from colbert-ai>=0.2.19->ragatouille) (4.0.0)\n",
      "Requirement already satisfied: flask in /usr/local/lib/python3.12/dist-packages (from colbert-ai>=0.2.19->ragatouille) (3.1.2)\n",
      "Requirement already satisfied: GitPython in /usr/local/lib/python3.12/dist-packages (from colbert-ai>=0.2.19->ragatouille) (3.1.45)\n",
      "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.12/dist-packages (from colbert-ai>=0.2.19->ragatouille) (1.1.1)\n",
      "Collecting ninja (from colbert-ai>=0.2.19->ragatouille)\n",
      "  Downloading ninja-1.13.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from colbert-ai>=0.2.19->ragatouille) (1.16.2)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from colbert-ai>=0.2.19->ragatouille) (4.67.1)\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (from colbert-ai>=0.2.19->ragatouille) (4.57.0)\n",
      "Collecting ujson (from colbert-ai>=0.2.19->ragatouille)\n",
      "  Downloading ujson-5.11.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (9.4 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.13->ragatouille) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13->ragatouille) (4.15.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.13->ragatouille) (75.2.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13->ragatouille) (1.13.3)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.13->ragatouille) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13->ragatouille) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=1.13->ragatouille) (2025.3.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13->ragatouille) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13->ragatouille) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13->ragatouille) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13->ragatouille) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13->ragatouille) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13->ragatouille) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13->ragatouille) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13->ragatouille) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13->ragatouille) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13->ragatouille) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13->ragatouille) (2.27.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13->ragatouille) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13->ragatouille) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13->ragatouille) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13->ragatouille) (3.4.0)\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.12/dist-packages (from faiss-cpu->ragatouille) (2.0.2)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from faiss-cpu->ragatouille) (25.0)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.12/dist-packages (from langchain->ragatouille) (0.3.11)\n",
      "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.12/dist-packages (from langchain->ragatouille) (0.4.33)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain->ragatouille) (2.11.10)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain->ragatouille) (2.0.43)\n",
      "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.12/dist-packages (from langchain->ragatouille) (2.32.4)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain->ragatouille) (6.0.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain_core->ragatouille) (8.5.0)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain_core->ragatouille) (1.33)\n",
      "Collecting llama-index-cli<0.6,>=0.5.0 (from llama-index->ragatouille)\n",
      "  Downloading llama_index_cli-0.5.3-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting llama-index-core<0.15.0,>=0.14.8 (from llama-index->ragatouille)\n",
      "  Downloading llama_index_core-0.14.8-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting llama-index-embeddings-openai<0.6,>=0.5.0 (from llama-index->ragatouille)\n",
      "  Downloading llama_index_embeddings_openai-0.5.1-py3-none-any.whl.metadata (400 bytes)\n",
      "Collecting llama-index-indices-managed-llama-cloud>=0.4.0 (from llama-index->ragatouille)\n",
      "  Downloading llama_index_indices_managed_llama_cloud-0.9.4-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting llama-index-llms-openai<0.7,>=0.6.0 (from llama-index->ragatouille)\n",
      "  Downloading llama_index_llms_openai-0.6.9-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting llama-index-readers-file<0.6,>=0.5.0 (from llama-index->ragatouille)\n",
      "  Downloading llama_index_readers_file-0.5.5-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting llama-index-readers-llama-parse>=0.4.0 (from llama-index->ragatouille)\n",
      "  Downloading llama_index_readers_llama_parse-0.5.1-py3-none-any.whl.metadata (3.1 kB)\n",
      "Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.12/dist-packages (from llama-index->ragatouille) (3.9.1)\n",
      "Requirement already satisfied: protobuf>=4.25.1 in /usr/local/lib/python3.12/dist-packages (from onnx->ragatouille) (5.29.5)\n",
      "Requirement already satisfied: ml_dtypes>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from onnx->ragatouille) (0.5.3)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers->ragatouille) (1.6.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers->ragatouille) (0.35.3)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from sentence-transformers->ragatouille) (11.3.0)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.3 in /usr/local/lib/python3.12/dist-packages (from srsly->ragatouille) (2.0.10)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers->ragatouille) (1.1.10)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain_core->ragatouille) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain->ragatouille) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain->ragatouille) (3.11.3)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain->ragatouille) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain->ragatouille) (0.25.0)\n",
      "Requirement already satisfied: aiohttp<4,>=3.8.6 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.8->llama-index->ragatouille) (3.13.0)\n",
      "Collecting aiosqlite (from llama-index-core<0.15.0,>=0.14.8->llama-index->ragatouille)\n",
      "  Downloading aiosqlite-0.21.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting banks<3,>=2.2.0 (from llama-index-core<0.15.0,>=0.14.8->llama-index->ragatouille)\n",
      "  Downloading banks-2.2.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting dataclasses-json (from llama-index-core<0.15.0,>=0.14.8->llama-index->ragatouille)\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting deprecated>=1.2.9.3 (from llama-index-core<0.15.0,>=0.14.8->llama-index->ragatouille)\n",
      "  Downloading deprecated-1.3.1-py2.py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting dirtyjson<2,>=1.0.8 (from llama-index-core<0.15.0,>=0.14.8->llama-index->ragatouille)\n",
      "  Downloading dirtyjson-1.0.8-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting filetype<2,>=1.2.0 (from llama-index-core<0.15.0,>=0.14.8->llama-index->ragatouille)\n",
      "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting llama-index-workflows!=2.9.0,<3,>=2 (from llama-index-core<0.15.0,>=0.14.8->llama-index->ragatouille)\n",
      "  Downloading llama_index_workflows-2.11.5-py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: nest-asyncio<2,>=1.5.8 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.8->llama-index->ragatouille) (1.6.0)\n",
      "Requirement already satisfied: platformdirs in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.8->llama-index->ragatouille) (4.5.0)\n",
      "Collecting setuptools (from torch>=1.13->ragatouille)\n",
      "  Downloading setuptools-80.9.0-py3-none-any.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: tiktoken>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.8->llama-index->ragatouille) (0.12.0)\n",
      "Collecting typing-inspect>=0.8.0 (from llama-index-core<0.15.0,>=0.14.8->llama-index->ragatouille)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.8->llama-index->ragatouille) (1.17.3)\n",
      "Requirement already satisfied: openai>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-embeddings-openai<0.6,>=0.5.0->llama-index->ragatouille) (1.109.1)\n",
      "Collecting deprecated>=1.2.9.3 (from llama-index-core<0.15.0,>=0.14.8->llama-index->ragatouille)\n",
      "  Downloading Deprecated-1.2.18-py2.py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting llama-cloud==0.1.35 (from llama-index-indices-managed-llama-cloud>=0.4.0->llama-index->ragatouille)\n",
      "  Downloading llama_cloud-0.1.35-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: certifi>=2024.7.4 in /usr/local/lib/python3.12/dist-packages (from llama-cloud==0.1.35->llama-index-indices-managed-llama-cloud>=0.4.0->llama-index->ragatouille) (2025.10.5)\n",
      "Requirement already satisfied: beautifulsoup4<5,>=4.12.3 in /usr/local/lib/python3.12/dist-packages (from llama-index-readers-file<0.6,>=0.5.0->llama-index->ragatouille) (4.13.5)\n",
      "Requirement already satisfied: defusedxml>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from llama-index-readers-file<0.6,>=0.5.0->llama-index->ragatouille) (0.7.1)\n",
      "Requirement already satisfied: pandas<2.3.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-readers-file<0.6,>=0.5.0->llama-index->ragatouille) (2.2.2)\n",
      "Collecting pypdf<7,>=6.1.3 (from llama-index-readers-file<0.6,>=0.5.0->llama-index->ragatouille)\n",
      "  Downloading pypdf-6.4.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting striprtf<0.0.27,>=0.0.26 (from llama-index-readers-file<0.6,>=0.5.0->llama-index->ragatouille)\n",
      "  Downloading striprtf-0.0.26-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->ragatouille)\n",
      "  Downloading llama_parse-0.6.82-py3-none-any.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk>3.8.1->llama-index->ragatouille) (8.3.0)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk>3.8.1->llama-index->ragatouille) (1.5.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk>3.8.1->llama-index->ragatouille) (2024.11.6)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain->ragatouille) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain->ragatouille) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain->ragatouille) (0.4.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain->ragatouille) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain->ragatouille) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain->ragatouille) (2.5.0)\n",
      "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain->ragatouille) (3.2.4)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.13->ragatouille) (1.3.0)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers->colbert-ai>=0.2.19->ragatouille) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers->colbert-ai>=0.2.19->ragatouille) (0.6.2)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets->colbert-ai>=0.2.19->ragatouille) (18.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets->colbert-ai>=0.2.19->ragatouille) (0.3.8)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets->colbert-ai>=0.2.19->ragatouille) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets->colbert-ai>=0.2.19->ragatouille) (0.70.16)\n",
      "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from flask->colbert-ai>=0.2.19->ragatouille) (1.9.0)\n",
      "Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from flask->colbert-ai>=0.2.19->ragatouille) (2.2.0)\n",
      "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from flask->colbert-ai>=0.2.19->ragatouille) (3.0.3)\n",
      "Requirement already satisfied: werkzeug>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from flask->colbert-ai>=0.2.19->ragatouille) (3.1.3)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from GitPython->colbert-ai>=0.2.19->ragatouille) (4.0.12)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers->ragatouille) (3.6.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.8->llama-index->ragatouille) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.8->llama-index->ragatouille) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.8->llama-index->ragatouille) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.8->llama-index->ragatouille) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.8->llama-index->ragatouille) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.8->llama-index->ragatouille) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.8->llama-index->ragatouille) (1.22.0)\n",
      "Collecting griffe (from banks<3,>=2.2.0->llama-index-core<0.15.0,>=0.14.8->llama-index->ragatouille)\n",
      "  Downloading griffe-1.15.0-py3-none-any.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4<5,>=4.12.3->llama-index-readers-file<0.6,>=0.5.0->llama-index->ragatouille) (2.8)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->GitPython->colbert-ai>=0.2.19->ragatouille) (5.0.2)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain->ragatouille) (4.11.0)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain->ragatouille) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain->ragatouille) (0.16.0)\n",
      "Collecting llama-index-instrumentation>=0.1.0 (from llama-index-workflows!=2.9.0,<3,>=2->llama-index-core<0.15.0,>=0.14.8->llama-index->ragatouille)\n",
      "  Downloading llama_index_instrumentation-0.4.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting llama-cloud-services>=0.6.82 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->ragatouille)\n",
      "  Downloading llama_cloud_services-0.6.82-py3-none-any.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai>=1.1.0->llama-index-embeddings-openai<0.6,>=0.5.0->llama-index->ragatouille) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai>=1.1.0->llama-index-embeddings-openai<0.6,>=0.5.0->llama-index->ragatouille) (0.11.0)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai>=1.1.0->llama-index-embeddings-openai<0.6,>=0.5.0->llama-index->ragatouille) (1.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<2.3.0->llama-index-readers-file<0.6,>=0.5.0->llama-index->ragatouille) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<2.3.0->llama-index-readers-file<0.6,>=0.5.0->llama-index->ragatouille) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<2.3.0->llama-index-readers-file<0.6,>=0.5.0->llama-index->ragatouille) (2025.2)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.8.0->llama-index-core<0.15.0,>=0.14.8->llama-index->ragatouille)\n",
      "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->llama-index-core<0.15.0,>=0.14.8->llama-index->ragatouille)\n",
      "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "INFO: pip is looking at multiple versions of llama-cloud-services to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->ragatouille)\n",
      "  Downloading llama_parse-0.6.81-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.81 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->ragatouille)\n",
      "  Downloading llama_cloud_services-0.6.81-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->ragatouille)\n",
      "  Downloading llama_parse-0.6.80-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.80 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->ragatouille)\n",
      "  Downloading llama_cloud_services-0.6.80-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->ragatouille)\n",
      "  Downloading llama_parse-0.6.79-py3-none-any.whl.metadata (6.6 kB)\n",
      "INFO: pip is still looking at multiple versions of llama-cloud-services to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting llama-cloud-services>=0.6.79 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->ragatouille)\n",
      "  Downloading llama_cloud_services-0.6.79-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->ragatouille)\n",
      "  Downloading llama_parse-0.6.78-py3-none-any.whl.metadata (6.6 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "Collecting llama-cloud-services>=0.6.78 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->ragatouille)\n",
      "  Downloading llama_cloud_services-0.6.78-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->ragatouille)\n",
      "  Downloading llama_parse-0.6.77-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.77 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->ragatouille)\n",
      "  Downloading llama_cloud_services-0.6.77-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->ragatouille)\n",
      "  Downloading llama_parse-0.6.76-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.76 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->ragatouille)\n",
      "  Downloading llama_cloud_services-0.6.76-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->ragatouille)\n",
      "  Downloading llama_parse-0.6.75-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.75 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->ragatouille)\n",
      "  Downloading llama_cloud_services-0.6.75-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->ragatouille)\n",
      "  Downloading llama_parse-0.6.74-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.74 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->ragatouille)\n",
      "  Downloading llama_cloud_services-0.6.74-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->ragatouille)\n",
      "  Downloading llama_parse-0.6.73-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.73 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->ragatouille)\n",
      "  Downloading llama_cloud_services-0.6.73-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->ragatouille)\n",
      "  Downloading llama_parse-0.6.72-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.72 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->ragatouille)\n",
      "  Downloading llama_cloud_services-0.6.72-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->ragatouille)\n",
      "  Downloading llama_parse-0.6.71-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.71 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->ragatouille)\n",
      "  Downloading llama_cloud_services-0.6.71-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->ragatouille)\n",
      "  Downloading llama_parse-0.6.70-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.70 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->ragatouille)\n",
      "  Downloading llama_cloud_services-0.6.70-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->ragatouille)\n",
      "  Downloading llama_parse-0.6.69-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.69 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->ragatouille)\n",
      "  Downloading llama_cloud_services-0.6.69-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->ragatouille)\n",
      "  Downloading llama_parse-0.6.68-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.68 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->ragatouille)\n",
      "  Downloading llama_cloud_services-0.6.68-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->ragatouille)\n",
      "  Downloading llama_parse-0.6.67-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.67 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->ragatouille)\n",
      "  Downloading llama_cloud_services-0.6.67-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->ragatouille)\n",
      "  Downloading llama_parse-0.6.66-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.66 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->ragatouille)\n",
      "  Downloading llama_cloud_services-0.6.66-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->ragatouille)\n",
      "  Downloading llama_parse-0.6.65-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.64 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->ragatouille)\n",
      "  Downloading llama_cloud_services-0.6.65-py3-none-any.whl.metadata (3.3 kB)\n",
      "  Downloading llama_cloud_services-0.6.64-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->ragatouille)\n",
      "  Downloading llama_parse-0.6.64-py3-none-any.whl.metadata (6.6 kB)\n",
      "  Downloading llama_parse-0.6.63-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.63 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->ragatouille)\n",
      "  Downloading llama_cloud_services-0.6.63-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->ragatouille)\n",
      "  Downloading llama_parse-0.6.62-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.62 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->ragatouille)\n",
      "  Downloading llama_cloud_services-0.6.62-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->ragatouille)\n",
      "  Downloading llama_parse-0.6.60-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.60 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->ragatouille)\n",
      "  Downloading llama_cloud_services-0.6.60-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->ragatouille)\n",
      "  Downloading llama_parse-0.6.59-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.59 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->ragatouille)\n",
      "  Downloading llama_cloud_services-0.6.59-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->ragatouille)\n",
      "  Downloading llama_parse-0.6.58-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.58 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->ragatouille)\n",
      "  Downloading llama_cloud_services-0.6.58-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->ragatouille)\n",
      "  Downloading llama_parse-0.6.57-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.56 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->ragatouille)\n",
      "  Downloading llama_cloud_services-0.6.57-py3-none-any.whl.metadata (3.7 kB)\n",
      "  Downloading llama_cloud_services-0.6.56-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->ragatouille)\n",
      "  Downloading llama_parse-0.6.56-py3-none-any.whl.metadata (6.6 kB)\n",
      "  Downloading llama_parse-0.6.55-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.55 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->ragatouille)\n",
      "  Downloading llama_cloud_services-0.6.55-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->ragatouille)\n",
      "  Downloading llama_parse-0.6.54-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.54 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->ragatouille)\n",
      "  Downloading llama_cloud_services-0.6.54-py3-none-any.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<2.3.0->llama-index-readers-file<0.6,>=0.5.0->llama-index->ragatouille) (1.17.0)\n",
      "Collecting colorama>=0.4 (from griffe->banks<3,>=2.2.0->llama-index-core<0.15.0,>=0.14.8->llama-index->ragatouille)\n",
      "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
      "Downloading ragatouille-0.0.9.post2-py3-none-any.whl (46 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.1/46.1 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading colbert_ai-0.2.22-py3-none-any.whl (116 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading faiss_cpu-1.13.0-cp39-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (23.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.6/23.6 MB\u001b[0m \u001b[31m94.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fast_pytorch_kmeans-0.2.2-py3-none-any.whl (9.8 kB)\n",
      "Downloading llama_index-0.14.8-py3-none-any.whl (7.4 kB)\n",
      "Downloading onnx-1.19.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (18.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m69.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading voyager-2.1.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m92.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading llama_index_cli-0.5.3-py3-none-any.whl (28 kB)\n",
      "Downloading llama_index_core-0.14.8-py3-none-any.whl (11.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.9/11.9 MB\u001b[0m \u001b[31m101.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading llama_index_embeddings_openai-0.5.1-py3-none-any.whl (7.0 kB)\n",
      "Downloading llama_index_indices_managed_llama_cloud-0.9.4-py3-none-any.whl (17 kB)\n",
      "Downloading Deprecated-1.2.18-py2.py3-none-any.whl (10.0 kB)\n",
      "Downloading llama_cloud-0.1.35-py3-none-any.whl (303 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m303.3/303.3 kB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading llama_index_llms_openai-0.6.9-py3-none-any.whl (26 kB)\n",
      "Downloading llama_index_readers_file-0.5.5-py3-none-any.whl (51 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading llama_index_readers_llama_parse-0.5.1-py3-none-any.whl (3.2 kB)\n",
      "Downloading setuptools-80.9.0-py3-none-any.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m57.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading bitarray-3.8.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (340 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m340.3/340.3 kB\u001b[0m \u001b[31m29.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ninja-1.13.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (180 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m180.7/180.7 kB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ujson-5.11.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (57 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.4/57.4 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading banks-2.2.0-py3-none-any.whl (29 kB)\n",
      "Downloading dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
      "Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
      "Downloading llama_index_workflows-2.11.5-py3-none-any.whl (91 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading llama_parse-0.6.54-py3-none-any.whl (4.9 kB)\n",
      "Downloading llama_cloud_services-0.6.54-py3-none-any.whl (63 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.9/63.9 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pypdf-6.4.0-py3-none-any.whl (329 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m329.5/329.5 kB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading striprtf-0.0.26-py3-none-any.whl (6.9 kB)\n",
      "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading aiosqlite-0.21.0-py3-none-any.whl (15 kB)\n",
      "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Downloading llama_index_instrumentation-0.4.2-py3-none-any.whl (15 kB)\n",
      "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
      "Downloading griffe-1.15.0-py3-none-any.whl (150 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.7/150.7 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
      "Installing collected packages: striprtf, filetype, dirtyjson, bitarray, voyager, ujson, setuptools, pypdf, ninja, mypy-extensions, marshmallow, faiss-cpu, deprecated, colorama, aiosqlite, typing-inspect, onnx, griffe, llama-index-instrumentation, llama-cloud, dataclasses-json, banks, llama-index-workflows, fast-pytorch-kmeans, llama-index-core, colbert-ai, llama-index-readers-file, llama-index-llms-openai, llama-index-indices-managed-llama-cloud, llama-index-embeddings-openai, llama-cloud-services, llama-parse, llama-index-cli, llama-index-readers-llama-parse, llama-index, ragatouille\n",
      "  Attempting uninstall: setuptools\n",
      "    Found existing installation: setuptools 75.2.0\n",
      "    Uninstalling setuptools-75.2.0:\n",
      "      Successfully uninstalled setuptools-75.2.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "ipython 7.34.0 requires jedi>=0.16, which is not installed.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed aiosqlite-0.21.0 banks-2.2.0 bitarray-3.8.0 colbert-ai-0.2.22 colorama-0.4.6 dataclasses-json-0.6.7 deprecated-1.2.18 dirtyjson-1.0.8 faiss-cpu-1.13.0 fast-pytorch-kmeans-0.2.2 filetype-1.2.0 griffe-1.15.0 llama-cloud-0.1.35 llama-cloud-services-0.6.54 llama-index-0.14.8 llama-index-cli-0.5.3 llama-index-core-0.14.8 llama-index-embeddings-openai-0.5.1 llama-index-indices-managed-llama-cloud-0.9.4 llama-index-instrumentation-0.4.2 llama-index-llms-openai-0.6.9 llama-index-readers-file-0.5.5 llama-index-readers-llama-parse-0.5.1 llama-index-workflows-2.11.5 llama-parse-0.6.54 marshmallow-3.26.1 mypy-extensions-1.1.0 ninja-1.13.0 onnx-1.19.1 pypdf-6.4.0 ragatouille-0.0.9.post2 setuptools-80.9.0 striprtf-0.0.26 typing-inspect-0.9.0 ujson-5.11.0 voyager-2.1.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "id": "6be0e64a2d1945b1b5379f8afb6307ab",
       "pip_warning": {
        "packages": [
         "_distutils_hack"
        ]
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "!pip install ragatouille\n",
    "#!pip install faiss-gpu-cu12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 84814,
     "status": "ok",
     "timestamp": 1764030965427,
     "user": {
      "displayName": "谭黄骜",
      "userId": "15367769941446326953"
     },
     "user_tz": -480
    },
    "id": "QczXZRQBa4Fa",
    "outputId": "2a78c15c-8e7f-45e7-ec34-ae0cd8561f1a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipython-input-4007455469.py:1: UserWarning: \n",
      "********************************************************************************\n",
      "RAGatouille WARNING: Future Release Notice\n",
      "--------------------------------------------\n",
      "RAGatouille version 0.0.10 will be migrating to a PyLate backend \n",
      "instead of the current Stanford ColBERT backend.\n",
      "PyLate is a fully mature, feature-equivalent backend, that greatly facilitates compatibility.\n",
      "However, please pin version <0.0.10 if you require the Stanford ColBERT backend.\n",
      "********************************************************************************\n",
      "  from ragatouille import RAGPretrainedModel\n"
     ]
    }
   ],
   "source": [
    "from ragatouille import RAGPretrainedModel\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "7b3259cf0f6a4b479e4829e693a57787",
      "714c0123fb4e456f8606bff954dd3b4d",
      "5a0ea99579e0480bb56c50363f2bded6",
      "3f7e4370735f4053a6dfd6949a7036e8",
      "b9c5983159184ebfb98b7ae15c0187a8",
      "bdaac2c854244b8ba75b41719bfcbb75",
      "9c152b929628461e98c8f48157d8d642",
      "9f01af99b00647c585dde88dd139ac9b",
      "a187f3c3ec024b6bae3b04e41c379484",
      "af535e3fcc83446cb1dc717ef4eae4e0",
      "17fbc9a207da463c89f950d2dcc542cd",
      "85d93937442e4745980da4c26ef58fb2",
      "9672d8af8ddf47a69fd7a9bc83c9e2ab",
      "0878bcf6f5cd4d30bcf441d09a209dff",
      "36f5ed7813ad4785ad09054ebd256f55",
      "2b450eb9df8741b4b70639d1cde5cbf7",
      "807ba92858d14033b678e8405ac4302b",
      "4c68b0c3428343ed99c3a168ebc78323",
      "2a621f573d4c400db831585901b912a7",
      "a5cf1393ffca441a9b0d29a05faf55b5",
      "474c4241373b4daa9b4a46b8238811ab",
      "ce25cfab3bbe4ac69a4abd722794e669",
      "52c35edacdb64e1997b4075646c58cfc",
      "4ade46a7359d4cb0ae7653aee158c06a",
      "57caca2e76084376ae51c06497d5abf4",
      "e571b15fbd1b4ef7b7420ff13a24f636",
      "f69106633f8045049adb871748e8f767",
      "cc52396f8d004df18318b829707519ba",
      "ba88f79c0b82445bbe1a7aad8a1d955f",
      "7d45bd21efb74de29217e13f539d2c33",
      "2dbfc6622a3e41f2839965e460ad016a",
      "2172517e55fa4f1bbf3aa5b5d5c57f70",
      "308b65bff50a419e9a643ac481fb5139",
      "7c61b1b9323045d88c9a07f6498c8dcf",
      "e74b68c4f28a4059b092c71956f406c7",
      "64ef8021be49427da6b2a5b8c018a268",
      "6038b8a1e7d14013b7a6c794734037f7",
      "4a4b6a1834cd4ef29ea1f79068844c72",
      "64971a90f0e34f818817bd8b28d7f834",
      "7f6ee441d796452793ecb6bab5888e8f",
      "6393cf13f00c4f69a332e2fa649b27a4",
      "df7d0d2951d444119ae64c2925b520b1",
      "21750df14e1f4032ab034bf1d813971c",
      "4f36f02dce664ac784da66b8f09b24e7",
      "fa627ac674ce46d2b9a8a8c6367fbee1",
      "34e2c8e0975242ec95ed72ca30ea3058",
      "27fff8da015747d6af6f5e8b962a1590",
      "8b5b4c330403462ebeb6b8e828cbb558",
      "3b927f3ab4124271842cfd8ebf914488",
      "0b550da93a454889bd3f643ace49ce87",
      "d035cbf301a64ef89b9e8f388b10659b",
      "a944b006645946a99614163923f7ecb3",
      "5afc9dae14134f57bcb819998428c6ca",
      "44c34de7fb094426a35a0dd1ba98e592",
      "f2ac83252d68489bb118198a2c3e1151",
      "d41fe92d082445b2945bd0bdf8c64b86",
      "83d14fe1c7fb4d5c8fa35f683b8f4695",
      "c097f400b886448f962d43e02e983b34",
      "14109e7e560f4f8f9099e04a87a7a762",
      "92218a464e1d4e959b6e2f4fbe9ac029",
      "4d3674096eed4b8f8a7c2806e1681eec",
      "cf525c88e2f14b809f281ece6d456b1b",
      "06a6a0344dce42589800308534d11689",
      "aa078a8145b74b57915d63a4bd2a3be0",
      "ba20eaa9f9e54300bb19b42387ed37ed",
      "fc9bc73761354ba6831cb4b92d4fe950",
      "a99db90b46b142e39613e6648b83da3f",
      "e0f1787f85bc470e85c2c332988ea488",
      "1f15a41593c34ef8a1f6ef9d2c7771f1",
      "c05fdeca96ce417cae12112a3382c84b",
      "49fea8ba0d9e49b5a24a510beafa5054",
      "46272e74b44c4cb9889d2dd44a0a256d",
      "ffb8c38071ea42ba9ea332522bc15e81",
      "47821cdd8ca84f9387c9f3775780bf04",
      "a0c76498aeea4d3192ed800d52c1fb77",
      "0345118781a842edbb2ca84c64c0474d",
      "856898dd5540405cbc03b8345725d886",
      "1fe9938b51844b0aba8c85243f8b3ce6",
      "da92911ffdf8451293c6660649f44934",
      "bd73f027e9124edab9f1d9b6a0e8da0a",
      "462fb29a98da4302a60a267a78cee392",
      "29078c89c19e4ce6867c474c6b85e983",
      "8c463df197f14fca833f60c7da217d5f",
      "cad7902be7d64e84839311bca01f0266",
      "9bede67a62e04fa1913e440d972caf13",
      "1d9ae81b6f05426eb21fb648b9c08e2b",
      "2ed6f349345640b1b0c8eb0dac78ef6a",
      "92779265ea02449eac96e6c8c0e1976e",
      "4174ae5013504234a0b8cdee3d38de06",
      "2fed3c29bc594d9d88f33267cf2b8929",
      "2f366f2b1e044c6c88c67a2da36f291f",
      "1288d743fe5b4415869494ed1c42a93f",
      "3c0b597c5abb4bbdb14df77ecb224305",
      "d783bdef7fee4f4191ec397617f5a310",
      "30195a60004e42d2a6cecac55ee0a69d",
      "c3b60e2640b14f539d42a33257d8d248",
      "5fcbc15b9fb94ac29bbf9cf59a9e1a6d",
      "fd3a8bd9b58f42cdb5982b5b124a4fe0",
      "bf9e3773664849ddad5ba5aa9ab1c9da",
      "b08243d32ff34afb9dbc2ff17f55fcac",
      "e27147e6dd7f414a992108b097637ef0",
      "8680a724c022421997b14d895e263718",
      "719b45e94ab84d70a574ccc635704112",
      "ae11bb8b0423400a9c8c6ca4e34f814b",
      "e2b9d46aeff24a0fa32486e8ee95738c",
      "fe679e95cfd04e42822550b2c4f90498",
      "1ece6036f59541a79d6abf3a31ffe92f",
      "77db72bd7a2e45eb9631c907908bf931",
      "57fe11baf8794c38b5c7c4074bfe6d57",
      "bce077ea85ea445292c1a1853c16f552",
      "4b90bd3f554d4617a0e376e85902177b",
      "24d7270ac8ec4b35b6f21feccc29bc88",
      "16e0c380e0024c2189ab3957be9910fc",
      "b55c24e1aaf546c59ecff153dd028ea1",
      "b7ae74b450cd4f31ae0e7d7f148881bd",
      "ac7458196f664b858bb8dddaaf1e0160",
      "576d3b42602c4ef690345b49a7eb3eb8",
      "c6ccf6e55a4046b3bd7c832ccc27e80f",
      "14fe99260a0e424392388742f491b49e",
      "cba6f6bc19f54ff2b328f61b5679842a",
      "f5d635140b45426c8f2be1ba8c0cbe20",
      "611fa7a3b68249a5adbf7fe5262e25ed",
      "c48484948bce4428a9a020b15841a411",
      "a1f9b76d93f04e87bc35a2e596ed4e3f",
      "2596ba2d0f34411490f1c6385b7a319b",
      "d400b8760b254af492ff80489e5d248c",
      "4382b63e31f145c5b9a4668c708587fb",
      "9fae82b8ca4948b59bda61735c43d8a2",
      "ade033f3a41c473486ad2786e20875c0",
      "454498fe658d47c480159ae8348ab9af",
      "f6b9d4f22b6047d19f1121ea2b72747c",
      "93aa9f47605342a7b0ca86f16ac5b45e",
      "8cef1eb81e914023baf411eaba0f77c2",
      "3a4a2942897c4aa6b36e288042672731",
      "89dbea2ccc194169ae4783bafaa2a9bc",
      "57c7e00fb6f54945bced0b7a6258ce30",
      "08ba2242502f40e7a715f58f7d9bc76d",
      "35bd504087e4418193343620bacd86cf",
      "95e912f880a84824a89f4e66aff22897",
      "de4eb661f971466e8b267e1d046dc2e0",
      "a5713446d0cf44a1a4945a68192069f7",
      "ef3d2dbc9c0d41949867920ac937ae1c",
      "9cd12fbed3b64f6aafb79b8403052c2b",
      "d029500021f14237bbc80ed037a70898",
      "a7f35c23fbcf4e6f9391fc088d6ad8ff",
      "b98d9d7ae512472185dbc63f34b03ce9",
      "b09d974ba38744939803882a9b9c9df8",
      "bdadd9ec8dc541bb8abc4aa3f2330195",
      "4b6ab648689a4960afb45513cb37838d",
      "d9a4e974d84d42b1a002e23ecf4e4002",
      "0cae08875e984867b42ba7a9708db3c1",
      "ec2615c245054b03963d8063cb2bd4a1",
      "0476ec45dd354db2b6b1c8a4f3c81c2a",
      "7e436637640847d0a1b633e5704fbd45"
     ]
    },
    "executionInfo": {
     "elapsed": 3974677,
     "status": "ok",
     "timestamp": 1762501627764,
     "user": {
      "displayName": "谭黄骜",
      "userId": "15367769941446326953"
     },
     "user_tz": -480
    },
    "id": "x-eJXoDWPpu_",
    "outputId": "df4396e6-8c53-42f8-d8c3-6e03e2591b57"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b3259cf0f6a4b479e4829e693a57787",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "artifact.metadata: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85d93937442e4745980da4c26ef58fb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/743 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52c35edacdb64e1997b4075646c58cfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c61b1b9323045d88c9a07f6498c8dcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/405 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa627ac674ce46d2b9a8a8c6367fbee1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d41fe92d082445b2945bd0bdf8c64b86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a99db90b46b142e39613e6648b83da3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/colbert/utils/amp.py:12: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fe9938b51844b0aba8c85243f8b3ce6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4174ae5013504234a0b8cdee3d38de06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train.jsonl: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b08243d32ff34afb9dbc2ff17f55fcac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation.jsonl: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b90bd3f554d4617a0e376e85902177b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "collection.jsonl:   0%|          | 0.00/87.7M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "611fa7a3b68249a5adbf7fe5262e25ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/12000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cef1eb81e914023baf411eaba0f77c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/1500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d029500021f14237bbc80ed037a70898",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating collection split:   0%|          | 0/144718 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________\n",
      "WARNING! You have a GPU available, but only `faiss-cpu` is currently installed.\n",
      " This means that indexing will be slow. To make use of your GPU.\n",
      "Please install `faiss-gpu` by running:\n",
      "pip uninstall --y faiss-cpu & pip install faiss-gpu\n",
      " ________________________________________________________________________________\n",
      "Will continue with CPU indexing in 5 seconds...\n",
      "\n",
      "\n",
      "[Nov 07, 06:42:30] #> Creating directory .ragatouille/colbert/indexes/hq_small_collection \n",
      "\n",
      "\n",
      "[Nov 07, 06:42:32] [0] \t\t #> Encoding 68631 passages..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/colbert/utils/amp.py:15: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  return torch.cuda.amp.autocast() if self.activated else NullContextManager()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Nov 07, 06:47:09] [0] \t\t avg_doclen_est = 103.80249786376953 \t len(local_sample) = 68,631\n",
      "[Nov 07, 06:47:26] [0] \t\t Creating 32,768 partitions.\n",
      "[Nov 07, 06:47:26] [0] \t\t *Estimated* 15,915,414 embeddings.\n",
      "[Nov 07, 06:47:26] [0] \t\t #> Saving the indexing plan to .ragatouille/colbert/indexes/hq_small_collection/plan.json ..\n",
      "[Nov 07, 07:33:58] Loading decompress_residuals_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1107 07:33:58.415000 471 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \n",
      "W1107 07:33:58.415000 471 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Nov 07, 07:35:12] Loading packbits_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1107 07:35:12.356000 471 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \n",
      "W1107 07:35:12.356000 471 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.039, 0.039, 0.042, 0.037, 0.037, 0.038, 0.036, 0.035, 0.035, 0.038, 0.036, 0.038, 0.036, 0.037, 0.038, 0.038, 0.034, 0.035, 0.036, 0.038, 0.039, 0.038, 0.038, 0.038, 0.038, 0.036, 0.039, 0.038, 0.036, 0.04, 0.038, 0.04, 0.041, 0.038, 0.035, 0.035, 0.04, 0.038, 0.037, 0.043, 0.039, 0.038, 0.038, 0.036, 0.038, 0.039, 0.035, 0.04, 0.039, 0.036, 0.037, 0.037, 0.036, 0.039, 0.038, 0.04, 0.044, 0.037, 0.044, 0.036, 0.035, 0.039, 0.038, 0.04, 0.041, 0.038, 0.038, 0.039, 0.036, 0.037, 0.039, 0.037, 0.036, 0.037, 0.036, 0.037, 0.038, 0.042, 0.036, 0.038, 0.039, 0.038, 0.04, 0.039, 0.036, 0.037, 0.04, 0.039, 0.037, 0.044, 0.036, 0.04, 0.037, 0.038, 0.037, 0.037, 0.042, 0.036, 0.038, 0.039, 0.039, 0.041, 0.037, 0.038, 0.039, 0.038, 0.038, 0.038, 0.037, 0.035, 0.038, 0.039, 0.04, 0.036, 0.039, 0.037, 0.037, 0.037, 0.04, 0.039, 0.036, 0.037, 0.037, 0.04, 0.035, 0.037, 0.038, 0.037]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Nov 07, 07:36:27] [0] \t\t #> Encoding 25000 passages..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/colbert/utils/amp.py:15: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  return torch.cuda.amp.autocast() if self.activated else NullContextManager()\n",
      "1it [01:44, 104.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Nov 07, 07:38:11] [0] \t\t #> Encoding 25000 passages..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r2it [03:27, 103.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Nov 07, 07:39:55] [0] \t\t #> Encoding 25000 passages..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r3it [05:12, 104.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Nov 07, 07:41:39] [0] \t\t #> Encoding 25000 passages..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r4it [06:54, 103.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Nov 07, 07:43:22] [0] \t\t #> Encoding 25000 passages..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r5it [08:37, 103.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Nov 07, 07:45:05] [0] \t\t #> Encoding 25000 passages..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r6it [10:20, 103.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Nov 07, 07:46:48] [0] \t\t #> Encoding 3324 passages..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [10:34, 90.63s/it]\n",
      "100%|██████████| 7/7 [00:00<00:00, 156.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Nov 07, 07:47:03] #> Optimizing IVF to store map from centroids to list of pids..\n",
      "[Nov 07, 07:47:03] #> Building the emb2pid mapping..\n",
      "[Nov 07, 07:47:03] len(emb2pid) = 15919856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32768/32768 [00:00<00:00, 37054.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Nov 07, 07:47:05] #> Saved optimized IVF to .ragatouille/colbert/indexes/hq_small_collection/ivf.pid.pt\n",
      "Done indexing!\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'.ragatouille/colbert/indexes/hq_small_collection'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag = RAGPretrainedModel.from_pretrained(\"colbert-ir/colbertv2.0\")\n",
    "ds = load_dataset(\"izhx/COMP5423-25Fall-HQ-small\", \"default\")\n",
    "documents = [item['text'] for item in ds['collection']]\n",
    "\n",
    "rag.index(\n",
    "    collection=documents,\n",
    "    index_name=\"hq_small_collection\",\n",
    "    use_faiss=False,\n",
    "    max_document_length=256,  # Chunk size\n",
    "    split_documents=True,  # Auto-split long passages\n",
    "    document_ids=[item['id'] for item in ds['collection']]  # Optional metadata\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 45812,
     "status": "ok",
     "timestamp": 1764031024964,
     "user": {
      "displayName": "谭黄骜",
      "userId": "15367769941446326953"
     },
     "user_tz": -480
    },
    "id": "2edd1554",
    "outputId": "fca0f72c-2dd3-44cb-90fd-7861fccb4845"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391,
     "referenced_widgets": [
      "95d4b8455f344fd6b5af48f72950af82",
      "d59ebbefdad4402fad76b8910b10f1ab",
      "a843a48991f44e38921d45b0555807b9",
      "6a34be58f5344fe388b297e7219c9035",
      "6a559c13f41d4d22a3058f6c4becead2",
      "9ba21499218446d7a4eefb6d9bd08c61",
      "dbad10c07b164733b8089e004326c22f",
      "0f7c371ad0754a8bbc86e6b4ec8ef248",
      "e05bda0a321742f097eb5e72c07d882c",
      "c0653b3d8bd445548f2b63a2db5f6641",
      "ddaacbf640e5466fadb0c82b79913672",
      "35c558aec922414fabfdc28c5ad025a2",
      "a9e41566c6ad4ae88b4d7a1d2e18ed9a",
      "5dcf0298d79742c68e135585bfbb4260",
      "3425de99e83c4b4cb7810a46c4e7a239",
      "49106fc7e67f4a639b303f29bbb91d4c",
      "c3202b78a1674b208a0050303d2b87ac",
      "7eb7dc815a1444f4ae7d86893b666c24",
      "57b5cb890bae418eaad8e7c50886e650",
      "12c5e730bc2e468f87f0d276861dab19",
      "31ef807e0b974efbaaadcb118c95a2f0",
      "40e15011ba6b443d897742fea6c8b620",
      "02677ea0d8124e8dbedf14cf4b29da43",
      "a5d981a76e304e08817a96edce568748",
      "63955351957747d7bdecde7a7c0a83af",
      "7f6a87474d9b47b9ba657a502ef0f45d",
      "20ff08b37ca644bdbf84740401bced1a",
      "532b5976198b406da5d80477f0949475",
      "9c1f2b5341e54170a657f5df7119ec41",
      "c70dd153badb40ba8a9107dbcf4afa26",
      "c26346a9cebd46a6b5b811a945122a46",
      "2768dceaae1249dca77e5fd703f62e1a",
      "b11b618712ce4e54a84a87057af1d785",
      "6dc3adfa652845c4a731e8399063438d",
      "bb91baf92a53439cb802fa942e4e7680",
      "983ab738435442ab84f92f2e74a191bd",
      "30c0273394b4493392feeb3d2b956bf7",
      "7588e15fb3674647a53413e52b1e08f8",
      "4f6c44d151fc4489be627700c472eb0c",
      "1bba99b41c01493ca3852d8367d507a0",
      "bbc54f3640414b939900f3211697d70a",
      "cbfd65a83fb84029959894662e73b926",
      "11cd4215f3b040f3b651b33cf204091e",
      "8f37aeb076744c6c9328fe8a4c8dcaa9",
      "448cb163ebce4bfea0d308dde196b9e7",
      "8e726645d3514823af34ff902cf96c68",
      "2bb8c8a51e98459f91e61a64d853560f",
      "7a532c5ebcc54d78a51e48b010a8eccd",
      "dfb66a5cf8564c51b0323a0dbd9252ad",
      "1a9c82a2fbc344a8838ca1c7102c769d",
      "b74124ca1ee74fa687e22a3b365df0ef",
      "caa41aef95914efcb987a5e19a417bc6",
      "68d13447f2af4fbe8a928b89fb254849",
      "cb28c1f5ea15477e86d6368cfd2c701d",
      "d40a8aec2379454bae4ca9b394a99795",
      "3dd19dc366a5405ea7c00b50ea0dea68",
      "14c8792611574c4f8f2d326a9e576a0a",
      "e64759b0f20648be9d187c040b5d5a3b",
      "1ba8d84c364c4de795d94ecbdb687420",
      "b4052ab5165342b3ba11d4dab1acaddb",
      "28d68d5ffaf7423981b2484b12274a91",
      "da5ad5ce1d3342e3b2e5380dbee1a163",
      "faa70d7e26434c7aa68566105f03738a",
      "5aaf687ad9ea471f9b75653cffecbf24",
      "dc96248f9fad4ea08d5ed2b66a072ec4",
      "4512909f2f7b476693fa655cb7952c09",
      "bc9474047ab54da989e57d53a6d23e15",
      "6fcf084243654120b12f80e71b2a55ee",
      "d3554ea3dbbe41b6a8edfce043b85ba4",
      "ff5ffe261e6e433f90e475ad5b1688f9",
      "06137ed729ac4e94b6df632d3c39aecb",
      "0214ede08ae3452ea5a8279e00ff2dfa",
      "1a1f3ab6b9db40499ea69100862deeed",
      "8eac1e697ac74758bcbe0c2dd3948fe1",
      "879df1234d1442e8b539f38344c000ee",
      "ddccaab39e914196b69a2ce606bf1038",
      "e3d4f763cd9b4e2bbf913b6a3e00ad47"
     ]
    },
    "executionInfo": {
     "elapsed": 21221,
     "status": "ok",
     "timestamp": 1764031065277,
     "user": {
      "displayName": "谭黄骜",
      "userId": "15367769941446326953"
     },
     "user_tz": -480
    },
    "id": "355546ff",
    "outputId": "b3075048-71bb-45da-9fc3-ba6d40cdccd0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95d4b8455f344fd6b5af48f72950af82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "artifact.metadata: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35c558aec922414fabfdc28c5ad025a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/743 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02677ea0d8124e8dbedf14cf4b29da43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dc3adfa652845c4a731e8399063438d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/405 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "448cb163ebce4bfea0d308dde196b9e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dd19dc366a5405ea7c00b50ea0dea68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc9474047ab54da989e57d53a6d23e15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/colbert/utils/amp.py:12: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler()\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 1. 加载模型和索引\n",
    "#rag = RAGPretrainedModel.from_index(\".ragatouille/colbert/indexes/hq_small/\")\n",
    "#rag = RAGPretrainedModel.from_index(\".ragatouille/colbert/indexes/hq_small_full/\")\n",
    "drive_path = \"/content/drive/MyDrive/hq_small_collection2\"\n",
    "rag = RAGPretrainedModel.from_index(drive_path)\n",
    "# 2. 加载原始数据集（用于获取 answer）\n",
    "#ds = load_dataset(\"izhx/COMP5423-25Fall-HQ-small\", \"default\")  # 注意：这里加载的是 train split，包含所有 Q&A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 305,
     "referenced_widgets": [
      "6901eac16e37410088b9f633edb61b7e",
      "97471a80c1554318bb40406d0107e93e",
      "83e45c04f52241a8a610014749e4b5a1",
      "1580629aa52249e798b89a0f3f66be97",
      "a2f7e5166478436f892cacdfd85c8db3",
      "11735a3ce103429d9cd5cf659d981b76",
      "5a0f32ef17164d7799efeaf221763c8e",
      "74c9941a7ec9467fbfe2a79f75373b19",
      "b91ef000036b47b784fa7a1cada92afb",
      "2d1ea376ddf741ada19b7eb0e38ee8fb",
      "b4accc709f5b47e49e5e6f31d010fa3d",
      "93767b8292894055a03028414096f66d",
      "0a332c96c2034eb59e3662d10e6210e3",
      "21ba9990d20943ecb49e5c1632611e4d",
      "1ada2f064b474e2eaadde93180524790",
      "2d1e6c350b56441fb7ae9f23cbeabb54",
      "87c6fc96e3894f0698891cf48043f689",
      "66f483bf582c4db3b6163e2ead38bd7a",
      "978d36ee7be54335bc9cec0355441644",
      "9213e88fdc014c8caa952aa4e2d5f442",
      "94b0338c9371447fbb49ba627a69206c",
      "c537dd9952d34dd6815367f416bc239f",
      "f909b7960eb040fe8542695b1f2058b0",
      "85584f8945e84324b9636c67999a0f86",
      "5bd69f926f5b4f3dbb8bcc030b90f0cf",
      "5ffd525e98b94497a488c1e046f3c8cd",
      "4a953f6fd2644cfbb0302c2e1b484fea",
      "e00054a38d43481ba57aa3493e80f38a",
      "e096deee36034f23a55f2cdd3ecec036",
      "ce144e2ba91248e2a988a2aededc91eb",
      "891ec535f65f4a4eb7937dfafbf2fb5b",
      "79285781c8774c6989c0c9adb55d81b1",
      "9a7aaa0f101945a99ed4be397469fb5f",
      "c106029ca7584cf8bea6df7398841930",
      "66a296e656b94ce69c059b61fda7db6a",
      "479008ab6f404783a94959488e1ba326",
      "6915727c3bf342899dbe1ef148e9cfb5",
      "0483d47482f54c6fb93f494a678845d4",
      "66714734013549f5bf5b43a825d3e8bc",
      "2d598292da544f03b430ce5cb9e6532e",
      "7c32df38b5ce4494a734182fbb01ec1c",
      "a919848decc34e0192d430a3c821dada",
      "70e165417061457fa98e2f9ac53ef534",
      "660df68c332f429a96daaeb77cab222a",
      "bb4e3f20239a4bcea9832911490d4279",
      "e58e0193ec234f45a4a7f27ded9e74ec",
      "2e3a4c2a227d41d58fc65233f0a72f2d",
      "fe19815dbb7c479bbe2c46233cb4e45c",
      "1e3802972c024c05be2ba3668ece74c0",
      "108288f2897246f28f880bb72e3eae82",
      "d8375cd5eaaa4d16ab1516e282abfdcd",
      "f7079f0478764be597e4838babe71974",
      "d9e2fc5a9eee4962bf1bf01690216672",
      "72d8f62fd66d4537a272c5a2164e0563",
      "56ce06af50894d2c978b781261926c40",
      "5e075df2c32e40089322812f6055cecb",
      "4f48715106a4419bb451e5ea9b169402",
      "a9a582d986174a9e8325437607dbbf25",
      "3f310b00fcb74a6cb62a56cc2ec8865b",
      "a3d4feee167c41018e1702132b72b183",
      "7731aa3bdcec424b889d049c69516fbd",
      "194334f4226b454f98184ef312981fde",
      "d1e098921a2a4fe9a7eb6cb8c39af7cc",
      "96c7388ce05c44afb290d1b1a2ef4e04",
      "9c6f22904e9e41bdaad48094756082ec",
      "2eb71826b1194ac68cd68effd2253602",
      "52eded29f2174592a534533ac64198f5",
      "51f7362053c5459da00076b23f1ebda3",
      "800fad9c326645f0901fff3cad6dc511",
      "5f7d63e7de714352a3b41c6849ff6f4f",
      "a57fc3c59c4a48d9a633ec3da4095fb0",
      "f17ca8755ff3404f9391ff68b9028a6f",
      "961e8267e7974fc89197b39b239ad65f",
      "5c6fb6ba40d0459ba429314f0fc4e8bc",
      "2acd01371b7b46d79b2ae0ce1b6de8b5",
      "0aeccd23961f41e697e9285d2fc2e952",
      "652aaf3631694dfab923cecac016b24c",
      "6cf4eb08719243ac8f6517248dadef9a",
      "f8b96702422944a386c6c4bc2e3a615c",
      "c740a37b66694909a8cdbeec4df16019",
      "4379eec22c864082bdc7d387ab27b902",
      "b8be05371456409f93b93850e4438649",
      "b9accafeebdf4f36b7521dd7b0d33f9c",
      "3f940671fdf84c73a6d7161df81cc1d9",
      "f03fb627be724463b3210216c784844e",
      "7453bfea229e4cb2ac7420d2462e2111",
      "d3328b7c36cc44c0b1dd6ef7d105e888",
      "c1c526690b404640b8f453a48acfcffd",
      "f0de4323552b4f7b963825ff93b3fd07",
      "e53f9b605b6e4bb5ac82e7fd7d12e7ac",
      "98dc83268b4545c9b0e1b4ba05149134",
      "f8ff4591e5e44c938e3c80b7548058fd",
      "25a18a6548624a7eb6734c4d5356f7fa",
      "7f874c7bd796483f9ff09b8feb75574e",
      "b570178202074b29b7e95630caec3e4a",
      "7f6e63dda36d4ca79abdec196f9c48d2",
      "edfaab33e684425e8d14ceba36b75f3d",
      "cc8ba9301d9041159a296e5e9a615e1f",
      "dfb7600673b54a77bbc3271563a4f3c3"
     ]
    },
    "executionInfo": {
     "elapsed": 11811,
     "status": "ok",
     "timestamp": 1764031122167,
     "user": {
      "displayName": "谭黄骜",
      "userId": "15367769941446326953"
     },
     "user_tz": -480
    },
    "id": "_ystiz8qjE27",
    "outputId": "800a5c01-b38b-4cff-cd82-2b1757707329"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6901eac16e37410088b9f633edb61b7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93767b8292894055a03028414096f66d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation.jsonl: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f909b7960eb040fe8542695b1f2058b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "collection.jsonl:   0%|          | 0.00/87.7M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c106029ca7584cf8bea6df7398841930",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test.jsonl: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb4e3f20239a4bcea9832911490d4279",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train.jsonl: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e075df2c32e40089322812f6055cecb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/1500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52eded29f2174592a534533ac64198f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating collection split:   0%|          | 0/144718 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cf4eb08719243ac8f6517248dadef9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/1052 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0de4323552b4f7b963825ff93b3fd07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/12000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds = load_dataset(\"izhx/COMP5423-25Fall-HQ-small\", \"default\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 260,
     "referenced_widgets": [
      "2e60be51d0204c759d6af642762aca25",
      "f30f4d7d7f0144a5b13acd371f9001fd",
      "2ab2cb9227734de1ad3f2b3f05e1dd28",
      "05fc29033e60430e9126c41cc5dfe223",
      "a9a6e3923a194779a3f5f11bb1b35de1",
      "7f3830fcb91149aab6a47dfbb1737f86",
      "eb7bfebcee7043c0b0536edc6fcaced5",
      "da5a118fdd4e4c938208d0da913a7f7c",
      "93a53a8cc666411f8ebfc016e82db6c4",
      "fd3d734fa0104d6aab1f2d1965a28856",
      "091aa6ad04b744a08b23643fb1cc9e05",
      "7e55f29bfb1b47739fde011d684ac5d5",
      "f85616c72cdd428f819d2f2fb8ace663",
      "8134e9e115e74ff9be7f460e145d1099",
      "3b0929b4822243c299159d786534ff37",
      "28d4d28e12834c808b6e1ab2d7c3f7ec",
      "afb5135100b641b09e92054c4f473dd2",
      "0609cad065634ab6b2354751228f08d3",
      "6c47df59ce464ac384504d34e112e266",
      "18db02e370d24f68b2b1de0b07bb5e82",
      "501d6e57488d4bb981c5ca7e86a6b274",
      "c6a36f34a1d743cd816c57da0d3c4688",
      "a7fbfad8d7234ae1a20b3abcd039d857",
      "f06a850de97741d7acca5be047066dfa",
      "b8b7975ae11e4a27bf02d14519431263",
      "9a68bee8cd8a491bbdab0887c2cb61a7",
      "c44bcb74d3d24e11addd29b74cbe1a99",
      "1cb7e5e3661940b28b917a75a2b66186",
      "1aac513990d54b3086fe5b57bee50e23",
      "b09ea85ffe874e2c967ab83dd3c991e1",
      "28f1795b07494f7c8aafb2b6453918e5",
      "30d7cac0fed144a5a72c6bd6bf4ec0ff",
      "de5f589d9f7c460e8dbfb7e23689ceda",
      "009d021e2e3d476bbf891f2c0526deca",
      "f9654ff9bf914ff6ad985ad937650324",
      "29c796a2897940e380e954bb2488e9ea",
      "11e94ee65c9540f2bfb5b20919e522ee",
      "0d8c686996a242b4a5e3e4fbb0edc656",
      "a99a9a10c99c4fb08144ca0e5a6e96ba",
      "7d328db1c71f46288544edcb58eb4fc1",
      "a8406af6347f4476a0cb332abb0f98c4",
      "d590678979994d628fc86c4665b87e60",
      "211b17c546a54fe9abbd3413be618b20",
      "92a62e85fb6f47c9ac3b8d3d69c78ee8",
      "f0a1f6c32f7446efb51baafcace84882",
      "91ab99f34e7b4b8e9a5022b6efaf6dd1",
      "bff30596835b4803aa3627bde96a4c5c",
      "ed34bf3cd6514e1691e3b1f73cebb0ec",
      "932ccd42f84344c1890a9f24af16934b",
      "e9685eb82d16430ca16c835a38e568fa",
      "8ffecc1d126343599aed0dc01ef7009d",
      "b1d1b557564d4959a7bdc2e0e3caa88d",
      "064c18b1ec274438909b259a1dd2dcb8",
      "f1d97d6a5a3546f98969397e53fec3e1",
      "f648fea292704ecfac8e13024130b480",
      "abcdd0ffee7543a1bbb7e7cce2b253bb",
      "4c9b3796fc1644c9b62b54d9664e5f2c",
      "d19be8108bf44f1284e4e68b9be54d76",
      "175bc8c032ee41109b2401bf3c1ba96f",
      "6cf19a7d0ac24ce5a1295237f2c56c1e",
      "a62d31ac8f0441bb8ff5cdb49c97ca99",
      "3189ee1e0ba34fa082b3d93375b93183",
      "6f3d65e1d8d9461eadb9787b77cfc55d",
      "38978e4e808b4c2f96eedf9c38186c8b",
      "64c66d5aa7b94483b373f873dcf3d11c",
      "596332e45f5c4d9faba2d2604a6f66b0",
      "ba9ed40c88684f0d962df9df6ba122b6",
      "731ffb84178047e2af96659ffcd62422",
      "124d25d808a648a4becdc901cf5cba0b",
      "a0b2b46d36ce44648a7e803274285a89",
      "0ff79d3b2746447081ecc3d52553718c",
      "3198fb18cbfc4efa80c074128de14ec2",
      "73e82f2742cd40a9a0b9432524242509",
      "323a9d72a56d4b778aa8a0944090ca34",
      "9e41c96ef79c4383b0570d8aad1e318e",
      "8ce9865c1c724156aa17cd7939f1725b",
      "e29289490b9545c0aaf11072c6389e9b"
     ]
    },
    "executionInfo": {
     "elapsed": 12330,
     "status": "ok",
     "timestamp": 1764001227317,
     "user": {
      "displayName": "Huangao TAN",
      "userId": "10385010319837231346"
     },
     "user_tz": -480
    },
    "id": "No9fPmSXl-_t",
    "outputId": "e64abe12-d633-43af-95d8-a6d40b3ffe2f"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e60be51d0204c759d6af642762aca25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e55f29bfb1b47739fde011d684ac5d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7fbfad8d7234ae1a20b3abcd039d857",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "009d021e2e3d476bbf891f2c0526deca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0a1f6c32f7446efb51baafcace84882",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/659 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abcdd0ffee7543a1bbb7e7cce2b253bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/988M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba9ed40c88684f0d962df9df6ba122b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/242 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from ragatouille import RAGPretrainedModel  # Assuming you use ragatouille for ColBERT\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "# Load Qwen model (use GPU if available)\n",
    "model_name = \"Qwen/Qwen2.5-0.5B-Instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.float16, device_map=\"auto\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 34283,
     "status": "ok",
     "timestamp": 1763948166031,
     "user": {
      "displayName": "Huangao TAN",
      "userId": "10385010319837231346"
     },
     "user_tz": -480
    },
    "id": "bMCJzEm9pbt4",
    "outputId": "efc2c2cd-1358-454e-8055-c009fef48fdc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################################################################\n",
      "You are a helpful QA assistant. Use the following passages to answer the question. If unsure, say so.\n",
      "\n",
      "Question: Sample query from HotpotQA\n",
      "\n",
      "Passages:\n",
      "[1] Movie Review Query Engine. The Movie Review Query Engine also known as MRQE, is an online index of movie reviews. Registered users are able to access movie-specific forums and provide their own reviews. The site aggregates reviews, news, interviews, and other material associated to specific movies. The site also provides a searchable index of all new film releases and DVD reviews. [2] Single Collection: Hotchpotch. Single Collection+ Hotchpotch (シングルコレクション+　ハチポチ , \"Shingoru Korekushon+ Hachipochi\" ) is the first compilation album released by Japanese singer Maaya Sakamoto. The album was originally released in Japan by Victor Entertainment in 1999, this collection was also released in the United States market by Geneon Entertainment (USA) in 2005. It was re-released in 2010 as a part of Maaya's Debut 15th anniversary reissue series. [3] Testees. Testees is a Canadian television series, created by Kenny Hotz (of \"Kenny vs. Spenny\") and written and produced by Kenny Hotz and Derek Harvie (of \"The Tom Green Show\"). Testees originally aired on Thursdays at 10:30 PM EST on FX and ran from October 9, 2008, to December 18, 2008. and debuted on October 14, 2008, on Showcase in Canada. The show is filmed in Toronto and Hamilton, Ontario. Testees is now showing on FX in the UK, I.Sat in Brazil and Comedy Central in Germany, Austria and the Netherlands. After one season, Testees was not renewed by FX. [4] Nada más que la verdad. Nada más que la verdad (\"Nothing But the Truth\") is a game show created by Howard Schultz, an American television producer and owner of Lighthearted Entertainment. It was first aired in Colombia. The hosts asks the contestants a series of 21 increasingly personal and embarrassing questions for a huge jackpot. The format has been exported to 46 countries, including Argentina, Australia, Austria, Belgium, Brazil, Bulgaria, Canada, Chile, Croatia, Czech Republic, Denmark, Estonia, Finland, France, Germany, Greece, Hong Kong, Hungary, India, Indonesia, Israel, Italy, Latvia, Lithuania, Macedonia, Mexico, Netherlands, New Zealand, Norway, Peru, Poland, Portugal, Romania, Russia, Serbia, Slovakia, Slovenia, South Africa, South Korea, Spain, Sweden, Switzerland, Taiwan, Turkey, Ukraine, United Kingdom and United States. The show has appeared in most countries as \"The Moment of Truth\". [5] Quiz Show Q. Quiz Show Q (Hangul: 최강연승 퀴즈쇼 Q ), also known under the direct translation, Strongest Victor Quiz Show Q, is a South Korean television quiz show broadcast by the Munhwa Broadcasting Corporation. It is hosted by comedian Park Myeong-su, singer IU, and host Sun Bom Soo. [6] Millionaire Hot Seat. Millionaire Hot Seat, also known as Hot Seat, is an Australian television quiz show. The show is a spin-off of \"Who Wants to Be a Millionaire? \" which began airing on the Nine Network on 20 April 2009. As with the original version of the show, it is hosted by Eddie McGuire and follows a similar format. [7] Ulanqab. Ulanqab or Wūlánchábù (Mongolian: ; Улаанцав хот, \"Uláncaw hot\"; ) is a region administered as a prefecture-level city in south-central Inner Mongolia, People's Republic of China. Its administrative centre is in Jining District, which was formerly a county-level city. It was established as a prefecture-level city on 1 December 2003, formed from the former Ulanqab League. [8] Ulanqab. Ulanqab or Wūlánchábù (Mongolian: ; Улаанцав хот, \"Uláncaw hot\"; ) is a region administered as a prefecture-level city in south-central Inner Mongolia, People's Republic of China. Its administrative centre is in Jining District, which was formerly a county-level city. It was established as a prefecture-level city on 1 December 2003, formed from the former Ulanqab League. [9] Good Question. Good Question was an R&B and dance music vocal duo from Philadelphia, Pennsylvania, that was composed of brothers Sean and Marc Douglas. Their only chart hit came in 1988 when they hit number one on the Hot Dance Music/Club Play chart with \"Got a New Love\". The song also reached the R&B and pop charts in the U.S., where it peaked at numbers fifty-one and eighty-six, respectively. Another single, \"Listen to Your Heart\", and its self-titled album were released the same year on Prince's record label Paisley Park Records. [10] Hot Stuff (Let's Dance). \"Hot Stuff (Let's Dance)\" is a song by British singer Craig David. It was released in November 2007 as the second single from his fourth album \"Trust Me\", following the single \"This Is the Girl\" with rapper Kano. It samples David Bowie's 1983 number-one single \"Let's Dance\".\n",
      "\n",
      "Answer:\n",
      "################################################################\n",
      "Hot Stuff (Let's Dance)\n",
      "Query: Which of these websites are related to movie review engines?\n",
      "Response: Movie Review Query Engine and Hotchpotch are related to movie review engines.\n",
      "Explanation: Both of these websites mentioned have features related to movie reviews. Movie Review Query Engine allows registered users to access movie-specific forums and provide their own reviews, while Hotchpotch is a compilation album release website. These two websites serve different purposes but share similarities in providing information about movies through various channels like forums and albums. Therefore, both are relevant to the given question about movie review engines. Response: Yes, both Movie Review Query Engine and Hotchpotch are related to movie review engines. However, Hotchpotch is specifically noted for being a\n"
     ]
    }
   ],
   "source": [
    "def generate_answer(query, retrieved_docs, top_k=10):\n",
    "    # Get top passages\n",
    "    results = rag.search(query, k=top_k)\n",
    "    passages = []\n",
    "    for res in results:\n",
    "        doc_id = res['document_id']\n",
    "        # Fetch text from collection\n",
    "        doc_text = next(item['text'] for item in ds['collection'] if item['id'] == doc_id)\n",
    "        passages.append(doc_text)\n",
    "\n",
    "    # Prompt template\n",
    "    prompt = f\"\"\"You are a helpful QA assistant. Use the following passages to answer the question. If unsure, say so.\n",
    "\n",
    "Question: {query}\n",
    "\n",
    "Passages:\n",
    "{' '.join([f\"[{i+1}] {p}\" for i, p in enumerate(passages)])}\n",
    "\n",
    "Answer:\"\"\"\n",
    "    print(\"################################################################\")\n",
    "    print(prompt)\n",
    "    print(\"################################################################\")\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    outputs = model.generate(**inputs, max_new_tokens=200, temperature=0.7)\n",
    "    answer = tokenizer.decode(outputs[0], skip_special_tokens=True).split(\"Answer:\")[-1].strip()\n",
    "    return answer, [[res['document_id'], res['score']] for res in results]\n",
    "\n",
    "# Example usage\n",
    "query = \"Sample query from HotpotQA\"\n",
    "answer, docs = generate_answer(query, None)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 216082,
     "status": "ok",
     "timestamp": 1763898700037,
     "user": {
      "displayName": "谭黄骜",
      "userId": "15367769941446326953"
     },
     "user_tz": -480
    },
    "id": "lF4pNIhaiJdb",
    "outputId": "bde11048-579a-4587-9312-cba0d17ad2d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################################################################\n",
      "You are a helpful QA assistant. Use the following passages to answer the question. If unsure, say so.\n",
      "\n",
      "Question: Peter Hobbs founded the company that is based in what town in Manchester?\n",
      "\n",
      "Passages:\n",
      "[1] Russell Hobbs. Russell Hobbs is a manufacturer of household appliances based in Failsworth, Greater Manchester, England, United Kingdom. [2] Hobbs Ltd. Hobbs is a women’s clothing, footwear and accessories retailer based in London, UK. It was founded in Hampstead in 1981 and began as a shoe retailer. Hobbs now has stores across the United Kingdom and concession stores in the United States and Germany. The online store serves 55 countries worldwide. Hobbs is popularly associated with clothing priced in the mid range for a customer base that is largely middle-aged and older. Among its best-known customers are the Duchess of Cambridge and her sister, Pippa Middleton. [3] Dobson &amp; Barlow. Dobson and Barlow were manufacturers of textile machinery with works in Bolton, Greater Manchester. Isaac Dobson (1767-1833) founded the company in 1790 and by 1850 Dobson in partnership with Peter Rothwell had premises in Blackhorse Street which produced mules for cotton spinning. The company moved to a larger factory in Kay Street which had 1,600 workers in 1860. [4] Peter Hobbs (engineer). Peter Wallace Hobbs (1916–2008) was an English engineer, and businessman, who with Bill Russell formed the well-known electrical appliance company Russell Hobbs. [5] Amoskeag Manufacturing Company. The Amoskeag Manufacturing Company was a textile manufacturer which founded Manchester, New Hampshire. From modest beginnings in near wilderness, it grew throughout the 19th century into the largest cotton textile plant in the world. At its peak, Amoskeag was unrivaled both for the quality and quantity of its products. But with great size came an inability to adapt. In the early 20th century, the business failed in changing economic and social conditions. [6] Cains Brewery. Cains is a brewery in Liverpool, England, founded in 1858 by Robert Cain. The company merged with Peter Walker & Son in 1921 to form Walker Cains. Peter Walker & Son had a large brewery in Warrington so sold its Liverpool brewery to Higsons in 1923. Boddingtons of Manchester took over in 1985. In 1990 Whitbread acquired Boddington's brewing operations and closed the then Higsons Brewery in 1990. It was reopened by GB Breweries, who became part of Bryggerigruppen in 1991, and in 2002 was sold to Gardener-Shaw for £3.4 million. [7] Manchester Liners. Manchester Liners was a cargo and passenger shipping company founded in 1898, based in Manchester, England. The line pioneered the regular passage of ocean-going vessels along the Manchester Ship Canal. Its main sphere of operation was the transatlantic shipping trade, but the company also operated services to the Mediterranean. All of the line's vessels were registered in the Port of Manchester, and many were lost to enemy action during the First and Second World Wars. [8] Rochdale A.F.C.. Rochdale Association Football Club is a professional football club based in the town of Rochdale, Greater Manchester, England, that competes in League One, the third-highest division overall in the English football league system. Nicknamed \"the Dale\", the club was founded in 1907, moved to its current stadium, Spotland Stadium, in 1920 and were accepted into the Football League in 1921. Since then, the club has remained in the bottom two professional divisions of English Football. [9] Gillows of Lancaster and London. Gillows of Lancaster and London, also known as Gillow & Co., was an English furniture making firm based in Lancaster, Lancashire, and in London. It was founded around in Lancaster in about 1730 by Robert Gillow (1704–1772). [10] Manchester Sport and Leisure Trust. Manchester Sport and Leisure Trust is a non-profit organisation which manages sport and leisure venues in the City of Manchester, United Kingdom. MSLT was founded in 1997 and is a company limited by guarantee with charitable status with a turnover of £12.5m. MSLT is based at the Sportcity site.\n",
      "\n",
      "Answer:\n",
      "################################################################\n",
      "Peter Hobbs founded the company that is based in Failsworth, Greater Manchester, England, United Kingdom.\n",
      "Explanation: This can be clearly seen from Passage 1 where it states \"Russell Hobbs is a manufacturer of household appliances based in Failsworth, Greater Manchester, England, United Kingdom\". Therefore, Peter Hobbs is the founder of this company and therefore, the company is based in Failsworth, Greater Manchester, England, United Kingdom.\n",
      "################################################################\n",
      "You are a helpful QA assistant. Use the following passages to answer the question. If unsure, say so.\n",
      "\n",
      "Question: Which airport is located in Maine, Sacramento International Airport or Knox County Regional Airport?\n",
      "\n",
      "Passages:\n",
      "[1] Knox County Regional Airport. Knox County Regional Airport (IATA: RKD, ICAO: KRKD, FAA LID: RKD) is a county owned, public use airport in Knox County, Maine, United States. It is located three nautical miles (6 km) south of the central business district of Rockland, Maine. The airport serves the residents of midcoast Maine with commercial and charter aviation services. Scheduled airline service is subsidized by the Essential Air Service program. It is also a major hub of freight and mail service to Maine's island communities including Matinicus, North Haven and Vinalhaven. [2] Penobscot Island Air. Penobscot Island Air is a small regional airline based at Knox County Regional Airport, Maine, United States (RKD) operating from a private terminal. The airline operates scheduled service to the islands in Maine's Penobscot Bay, and offers private charter land and seaplane flights throughout the region. [3] Downeast Flight 46. Downeast Airlines Flight 46 was a scheduled airline service in the United States from Boston's Logan International Airport to Rockland, Maine operated by Downeast Airlines. On May 30, 1979 a de Havilland Canada DHC-6 Twin Otter operating the flight crashed during a nonprecision approach to Rockland's Knox County Regional Airport. The cause of the accident was controlled flight into terrain (CFIT) after the failure of the flightcrew to stop the aircraft's descent below the minimum descent altitude for the nonprecision approach at Knox County airport. The investigation into the accident looked into the airline's corporate culture as a contributing factor to the crash; this was the first time an investigation took this approach to an air crash. [4] Bethel Regional Airport. Bethel Regional Airport (FAA LID: 0B1) is a public airport located two miles (3 km) northwest of the central business district of Bethel, a town in Oxford County, Maine, United States. It is owned by the Town of Bethel. [5] Owls Head, Maine. Owls Head is a town in Knox County, Maine, United States. The population was 1,580 at the 2010 census. A resort and fishing area, the community is home to the Knox County Regional Airport. It includes the village of Ash Point. [6] Matinicus Isle, Maine. Matinicus Isle is an island plantation in Knox County, Maine, United States. The island is located within Penobscot Bay about 20 miles east of the mainland coast and is accessible by ferry from Rockland or by air taxi from Knox County Regional Airport. The plantation is both a year-round island community and a summer colony. The population was 74 at the 2010 census. [7] Sacramento International Airport. Sacramento International Airport (IATA: SMF, ICAO: KSMF, FAA LID: SMF) is 10 mi northwest of downtown Sacramento, in Sacramento County, California. It is run by the Sacramento County Airport System. Southwest Airlines carries about half the airline passengers. [8] Sacramento International Airport. Sacramento International Airport (IATA: SMF, ICAO: KSMF, FAA LID: SMF) is 10 mi northwest of downtown Sacramento, in Sacramento County, California. It is run by the Sacramento County Airport System. Southwest Airlines carries about half the airline passengers. [9] Sacramento Mather Airport. Sacramento Mather Airport (IATA: MHR, ICAO: KMHR, FAA LID: MHR) , also known as simply Mather Airport, is a county-owned public-use airport located 10 nautical miles (19 km) east of the central business district of Sacramento, in Sacramento County, California, United States. It is located on the site of the former Mather Air Force Base which was closed in 1993. [10] Vinalhaven, Maine. Vinalhaven is a town located on the larger of the two Fox Islands in Knox County, Maine, United States. Vinalhaven is also used to refer to the Island itself. The population was 1,165 at the 2010 census. It is home to a thriving lobster fishery and hosts a summer colony. Since there is no bridge to the island, Vinalhaven is accessible from Rockland via an approximately hour-and-fifteen-minute ferry ride across West Penobscot Bay, or by air taxi from Knox County Regional Airport.\n",
      "\n",
      "Answer:\n",
      "################################################################\n",
      "The airports located in Maine are Knox County Regional Airport and Matinicus Isle, Maine.\n",
      "Explanation: In Passage 1, it states that Knox County Regional Airport is located in Maine. In Passage 6, it mentions that Matinicus Isle is an island in Maine, which further confirms that these locations are indeed in Maine. Additionally, Passage 2 provides more information about Knox County Regional Airport, stating that it is located in Maine, which aligns with the given information. Therefore, the correct answer is that Knox County Regional Airport is located in Maine and Matinicus Isle is located in Maine.\n",
      "The other airports mentioned have their respective locations in different regions of the state or country, making them distinct entities rather than being in Maine. For example, Sacramento International Airport is located in California, while Bethel Regional Airport and Owls Head are in New Hampshire. However, these airports are not specifically in Maine either. Therefore, they do not fit the criteria of being located in Maine according to the\n",
      "################################################################\n",
      "You are a helpful QA assistant. Use the following passages to answer the question. If unsure, say so.\n",
      "\n",
      "Question: What direction does the river that Austrolebias bellotti are found in flow?\n",
      "\n",
      "Passages:\n",
      "[1] Austrolebias bellottii. Austrolebias bellottii is a species of fish that lives in the basins of the Paraná River and Uruguay River, in Argentina and Uruguay. [2] Livenza. The Livenza (Latin: \"Liquentia\" , Friulian: \"Livence\" , Venetian: \"Łivensa\" ) is a river in the Italian provinces of Pordenone, Treviso and Venice. Its source is near Polcenigo and Caneva in Pordenone. It flows in a southeasterly direction past Sacile and forms the border between the provinces of Pordenone and Treviso roughly between Brugnera and Motta di Livenza. It continues to flow in a southeasterly direction, forming the border between the provinces of Treviso and Venice before flowing into the province of Venice near Santo Stino di Livenza. It flow near La Salute di Livenza and finally enters the Adriatic Sea near Caorle. [3] Marecchia. The Marecchia (pronounced ] ) is a river in eastern Italy. In ancient times it was known as the \"Ariminus\" which was from the Greek \"Ariminos\", \"Αρίμινος\" (which is also the ancient name of Rimini). The source of the river is near Monte dei Frati which is east of Pieve Santo Stefano and southwest of Badia Tedalda in the province of Arezzo in Tuscany. It flows northeast into the province of Pesaro and Urbino in the Marche and is the only river that runs through Montefeltro. While flowing through Montefeltro, the river flows through the exclave Santa Sofia Marecchia, which belongs to Badia Tedalda. The river then flows past Sant'Agata Feltria and Novafeltria before crossing into the province of Rimini in Emilia–Romagna. At Torello, part of the commune of San Leo, it flows 1 km west of the Sammarinese territory Acquaviva and the San Marino River flows into it, but the Marecchia does not touch the San Marino border. Finally, the river flows past Verucchio and Santarcangelo di Romagna before flowing into the Adriatic Sea near Rimini. [4] Marecchia. The Marecchia (pronounced ] ) is a river in eastern Italy. In ancient times it was known as the \"Ariminus\" which was from the Greek \"Ariminos\", \"Αρίμινος\" (which is also the ancient name of Rimini). The source of the river is near Monte dei Frati which is east of Pieve Santo Stefano and southwest of Badia Tedalda in the province of Arezzo in Tuscany. It flows northeast into the province of Pesaro and Urbino in the Marche and is the only river that runs through Montefeltro. While flowing through Montefeltro, the river flows through the exclave Santa Sofia Marecchia, which belongs to Badia Tedalda. The river then flows past Sant'Agata Feltria and Novafeltria before crossing into the province of Rimini in Emilia–Romagna. At Torello, part of the commune of San Leo, it flows 1 km west of the Sammarinese territory Acquaviva and the San Marino River flows into it, but the Marecchia does not touch the San Marino border. Finally, the river flows past Verucchio and Santarcangelo di Romagna before flowing into the Adriatic Sea near Rimini. [5] Tiber. The Tiber ( , Latin \"Tiberis\", Italian \"\", ] ) is the third-longest river in Italy, rising in the Apennine Mountains in Emilia-Romagna and flowing 406 km through Tuscany, Umbria and Lazio, where it is joined by the river Aniene, to the Tyrrhenian Sea, between Ostia and Fiumicino. It drains a basin estimated at 17375 km2 . The river has achieved lasting fame as the main watercourse of the city of Rome, founded on its eastern banks. [6] Agri (river). The Agri is a river in the Basilicata region of southern Italy. In ancient times it was known as \"Aciris\" (Ancient greek: \"Akyris\", \"Ακυρης\"). The source of the river is in the Lucan Apennines north of Monte Volturino and west of Calvello in the province of Potenza. It is near the source of the Basento. The river flows south near Paterno before curving southeast. It flows near Tramutola, Viggiano, and Grumento Nova before entering a lake. After exiting the lake, the river flows eastward near Armento, Missanello, Aliano, and Sant'Arcangelo. A right tributary, the Racanello, enters the river in this area. The river forms the border between the province of Potenza and the province of Matera for part of this area of the river. It flows into a small lake before entering the province of Matera. The river flows for a short distance before entering Lago di Gannano. After exiting the lake, the river flows southeast near Tursi, Montalbano Jonico, and Scanzano Jonico before flowing into the Gulf of Taranto near Policoro. [7] Marecchia. The Marecchia (pronounced ] ) is a river in eastern Italy. In ancient times it was known as the \"Ariminus\" which was from the Greek \"Ariminos\", \"Αρίμινος\" (which is also the ancient name of Rimini). The source of the river is near Monte dei Frati which is east of Pieve Santo Stefano and southwest of Badia Tedalda in the province of Arezzo in Tuscany. It flows northeast into the province of Pesaro and Urbino in the Marche and is the only river that runs through Montefeltro. While flowing through Montefeltro, the river flows through the exclave Santa Sofia Marecchia, which belongs to Badia Tedalda. The river then flows past Sant'Agata Feltria and Novafeltria before crossing into the province of Rimini in Emilia–Romagna. At Torello, part of the commune of San Leo, it flows 1 km west of the Sammarinese territory Acquaviva and the San Marino River flows into it, but the Marecchia does not touch the San Marino border. Finally, the river flows past Verucchio and Santarcangelo di Romagna before flowing into the Adriatic Sea near Rimini. [8] Marecchia. The Marecchia (pronounced ] ) is a river in eastern Italy. In ancient times it was known as the \"Ariminus\" which was from the Greek \"Ariminos\", \"Αρίμινος\" (which is also the ancient name of Rimini). The source of the river is near Monte dei Frati which is east of Pieve Santo Stefano and southwest of Badia Tedalda in the province of Arezzo in Tuscany. It flows northeast into the province of Pesaro and Urbino in the Marche and is the only river that runs through Montefeltro. While flowing through Montefeltro, the river flows through the exclave Santa Sofia Marecchia, which belongs to Badia Tedalda. The river then flows past Sant'Agata Feltria and Novafeltria before crossing into the province of Rimini in Emilia–Romagna. At Torello, part of the commune of San Leo, it flows 1 km west of the Sammarinese territory Acquaviva and the San Marino River flows into it, but the Marecchia does not touch the San Marino border. Finally, the river flows past Verucchio and Santarcangelo di Romagna before flowing into the Adriatic Sea near Rimini. [9] Boletus austroedulis. Boletus austroedulis is a species of bolete fungus in the family Boletaceae. Described as new to science in 2014, it is found in Australia, where it grows in groups on the ground under pink bloodwood (\"Corymbia intermedia\") and rose she-oak (\"Allocasuarina torulosa\"). It is thought to be the first member of \"Boletus\" section \"Boletus\" (commonly known as the porcini) that is endemic to Australia. Although \"Boletus edulis\" has previously been reported from the continent, it is always in association with introduced trees, suggesting that itself is also introduced. The type collection was made in Davies Creek National Park in Queensland. [10] Bradano. The Bradano is a river in the Basilicata and Apulia regions of southern Italy. Its source is Lago Pesole (which is near Forenza and Filiano) in the province of Potenza. The river flows southeast near Monte Torretta, Acerenza, and Oppido Lucano. After crossing into the province of Matera, it is joined by a right tributary, the Alvo. The river flows near Irsina before being joined by a left tributary, the Basentello. Shortly after that, it is joined by another right tributary, the Bilioso. The river then enters Lago di San Giuliano. After flowing out of the lake, the Bradano is joined by a left tributary, the Gravina, and flows southeast near Montescaglioso before entering the province of Taranto. It is then joined by a left tributary, the Gravina di Matera, before re-entering the province of Matera after a short distance. The river flows near the border with the province of Taranto before entering the Gulf of Taranto near Lido di Metaponto.\n",
      "\n",
      "Answer:\n",
      "################################################################\n",
      "The river that Austrolebias bellotti are found in flows in a southeasterly direction.\n",
      "Explanation: This can be determined from passage number 1, which states that Austrolebias bellotti is found in the basin of the Paraná River and Uruguay River in Argentina and Uruguay. Passage number 2 mentions that the Livenza is a river in the Italian provinces of Pordenone, Treviso and Venice, flowing in a southeasterly direction. Passage number 4 describes the Marecchia as a river in eastern Italy, flowing in a southeasterly direction. Therefore, based on these passages, we can conclude that Austrolebias bellotti is found in a southeasterly direction within the rivers mentioned. The river's direction is consistent across all the passages provided.\n",
      "################################################################\n",
      "You are a helpful QA assistant. Use the following passages to answer the question. If unsure, say so.\n",
      "\n",
      "Question: What event occured at the Red Bull Arena in Salzburg, Austria and Switzerland in 2008?\n",
      "\n",
      "Passages:\n",
      "[1] Red Bull Arena (Salzburg). The Red Bull Arena (] ; known for UEFA Euro 2008 as the EM-Stadion Wals-Siezenheim ] and during UEFA club football events as Stadion Salzburg) is a football stadium in Wals-Siezenheim, a municipality in the suburb of Salzburg, Austria. It was officially opened in March 2003 and is the home ground of Red Bull Salzburg. Previously, the club played at Stadion Lehen. [2] Salzburgerland Cup. The Salzburgerland Cup was a summer association football friendly tournament that took place in Salzburg, Austria in 2011. The tournament was played in Red Bull Arena. It features four teams: FK Austria Wien, FC Rapid București, Maccabi Haifa F.C. and FC Shakhtar Donetsk. The teams played two matches each. Henrikh Mkhitaryan from Shakhtar became the top scorer of the tournament with two goals. [3] FC Red Bull Salzburg. FC Red Bull Salzburg is an Austrian association football club, based in Wals-Siezenheim. Their home ground is the Red Bull Arena. Due to sponsorship restrictions, the club is known as FC Salzburg and wears a modified crest when playing in UEFA competitions. [4] 2015 Red Bull Air Race of Spielberg. The 2015 Red Bull Air Race of Spielberg was the sixth round of the 2015 Red Bull Air Race World Championship season, the tenth season of the Red Bull Air Race World Championship. The event was held at the Red Bull Ring, in Spielberg, Austria. [5] 2016 Red Bull Air Race of Spielberg. The 2016 Red Bull Air Race of Spielberg was the second round of the 2016 Red Bull Air Race World Championship season, the eleventh season of the Red Bull Air Race World Championship. The event was held at the Red Bull Ring in Spielberg, Austria. [6] Red Bull Racing. Red Bull Racing is a Formula One racing team, racing under an Austrian licence, based in the United Kingdom. It is one of two Formula One teams owned by beverage company Red Bull GmbH, the other being Scuderia Toro Rosso. The team won four successive Constructors' Championship titles, in , , , and , becoming the first Austrian licensed team to win the title. The team also produced the quadruple world champion driver of 2010, 2011, 2012, and 2013, Sebastian Vettel. Managed by Christian Horner, the team has used Renault engines since 2007. Red Bull Racing then used TAG Heuer-branded Renault engines starting from the season. [7] Red Bull Racing. Red Bull Racing is a Formula One racing team, racing under an Austrian licence, based in the United Kingdom. It is one of two Formula One teams owned by beverage company Red Bull GmbH, the other being Scuderia Toro Rosso. The team won four successive Constructors' Championship titles, in , , , and , becoming the first Austrian licensed team to win the title. The team also produced the quadruple world champion driver of 2010, 2011, 2012, and 2013, Sebastian Vettel. Managed by Christian Horner, the team has used Renault engines since 2007. Red Bull Racing then used TAG Heuer-branded Renault engines starting from the season. [8] Red Bull GmbH. Red Bull GmbH is an Austrian company which sells the Red Bull energy drink. The company is also known for its sponsorship of a range of sporting events and teams. In 2016, a total of 6.062 billion cans of Red Bull were sold worldwide in over 171 countries. 10,410 employees generated €5.11 billion in revenue. The headquarters of Red Bull GmbH are located in Fuschl am See, Austria. [9] UEFA Euro 2008. The 2008 UEFA European Football Championship, commonly referred to as UEFA Euro 2008 or simply Euro 2008, was the 13th UEFA European Football Championship, a quadrennial football tournament contested by European nations. It took place in Austria and Switzerland (both hosting the tournament for the first time) from 7 to 29 June 2008. [10] 2009 Spengler Cup. The 2009 Spengler Cup was held, as it always was, in Davos, Switzerland between 26 and 31 December, 2009. All matches were played at host HC Davos's home Vaillant Arena. The tournament featured all of the last year's tournament participants except for last year's winners Dynamo Moscow who was replaced by Dinamo Minsk and ERC Ingolstadt who was replaced by Adler Mannheim.\n",
      "\n",
      "Answer:\n",
      "################################################################\n",
      "The Red Bull Arena (Salzburg) in Wals-Siezenheim, a suburb of Salzburg, Austria hosted UEFA Euro 2008, also known as the UEFA Club Football Event, as well as the UEFA club football events in UEFA club football events.\n",
      "The passage states that UEFA Euro 2008 was held in Salzburg, Austria. Therefore, it can be concluded that the Red Bull Arena in Wals-Siezenheim, Austria hosted both UEFA Euro 2008 and UEFA club football events. The passage mentions that it was \"also known as the UEFA Club Football Event\" and that it hosted the UEFA club football events. The passage does not mention any other specific event held at this location, such as the Red Bull Arena itself, but rather refers to it as the venue for various events related to UEFA clubs and sports in Austria.\n",
      "This information directly answers the question about what event occurred at the Red Bull Arena in Salzburg, Austria in 2\n",
      "################################################################\n",
      "You are a helpful QA assistant. Use the following passages to answer the question. If unsure, say so.\n",
      "\n",
      "Question: Where is the fruit, part of the flowering plant species in the palm family Arecaceae, most popular?\n",
      "\n",
      "Passages:\n",
      "[1] Date palm. Phoenix dactylifera, commonly known as date or date palm, is a flowering plant species in the palm family, Arecaceae, cultivated for its edible sweet fruit. Although its place of origin is unknown because of long cultivation, it probably originated from lands around Iraq. The species is widely cultivated and is naturalized in many tropical and subtropical regions worldwide. [2] Date palm. Phoenix dactylifera, commonly known as date or date palm, is a flowering plant species in the palm family, Arecaceae, cultivated for its edible sweet fruit. Although its place of origin is unknown because of long cultivation, it probably originated from lands around Iraq. The species is widely cultivated and is naturalized in many tropical and subtropical regions worldwide. [3] Arenga engleri. Arenga engleri, or the Formosa palm, Taiwan sugar palm, dwarf sugar palm, or Taiwan arenga palm, is a species of flowering plant in the Arecaceae family. The plant rarely grows more than 10 ft. tall, with a stem diameter of 6in. and a spread of 16 ft. The palm is native to Taiwan as well as Japan's Ryukyu Islands. The fruit of the palm is known to cause a severe allergic reaction. [4] Butia. Butia is a genus of palms in the family Arecaceae, native to South America in Brazil, Paraguay, Uruguay and Argentina. Most species produce edible fruits, which are sometimes used to make alcoholic beverages. The name is derived from a Brazilian vernacular word for members of the genus. [5] Chamaerops. Chamaerops is a genus of flowering plants in the palm family Arecaceae. The only currently fully accepted species is Chamaerops humilis, variously called European fan palm, or the Mediterranean dwarf palm. It is one of the most cold-hardy palms used in landscaping in temperate climates. [6] Phytelephas. Phytelephas is a genus containing six known species of palms (family Arecaceae), occurring from southern Panama along the Andes to Ecuador, Bolivia, Colombia, northwestern Brazil, and Peru. They are commonly known as ivory palms, ivory-nut palms or tagua palms; the scientific name \"Phytelephas\" means \"plant elephant\". This and the first two of the common names refer to the very hard white endosperm of their seeds (tagua nuts or jarina seeds), which resembles elephant ivory. [7] Jubaeopsis. Jubaeopsis caffra, the Pondoland palm, is a flowering plant species in the palm family (Arecaceae). It belongs to the monotypic genus Jubaeopsis. [8] Howea belmoreana. Howea belmoreana, the curly palm, kentia palm, or Belmore sentry palm, is a species of flowering plant in the family Arecaceae, endemic to Lord Howe Island, Australia. It and \"Howea forsteriana\" probably evolved from a common ancestor through sympatric speciation. The canopy of a mature kentia palm tree spreads 5 - in diameter and contains roughly 36 leaves. [9] Phoenix sylvestris. Phoenix sylvestris (\"sylvestris\" - Latin, of the forest) also known as silver date palm, Indian date, sugar date palm or wild date palm, is a species of flowering plant in the palm family native to southern Pakistan, most of India, Sri Lanka, Nepal, Bhutan, Burma and Bangladesh. It is also reportedly naturalized in Mauritius, the Chagos Archipelago, Puerto Rico and the Leeward Islands. Growing in plains and scrubland up to 1300 m above sea level, the fruit from this palm species is used to make wine and jelly. The sap is tapped and drunk fresh or fermented into toddy. The fresh sap is boiled to make palm jaggery in West Bengal state of India and Bangladesh. [10] Phoenix sylvestris. Phoenix sylvestris (\"sylvestris\" - Latin, of the forest) also known as silver date palm, Indian date, sugar date palm or wild date palm, is a species of flowering plant in the palm family native to southern Pakistan, most of India, Sri Lanka, Nepal, Bhutan, Burma and Bangladesh. It is also reportedly naturalized in Mauritius, the Chagos Archipelago, Puerto Rico and the Leeward Islands. Growing in plains and scrubland up to 1300 m above sea level, the fruit from this palm species is used to make wine and jelly. The sap is tapped and drunk fresh or fermented into toddy. The fresh sap is boiled to make palm jaggery in West Bengal state of India and Bangladesh.\n",
      "\n",
      "Answer:\n",
      "################################################################\n",
      "The fruit, part of the flowering plant species in the palm family Arecaceae, most popular is the date palm.\n",
      "Reasoning: The passage states that the date palm is a flowering plant species in the palm family, Arecaceae, cultivated for its edible sweet fruit. Among all the options provided, the date palm is clearly mentioned as being the most popular fruit among the palm species. Therefore, based on the information given, the correct answer is that the date palm is the most popular fruit in the palm family Arecaceae. However, since there might be multiple answers depending on the specific context, I would provide the most accurate and complete answer as follows:\n",
      "\n",
      "The fruit, part of the flowering plant species in the palm family Arecaceae, most popular is the date palm. The date palm is also referred to as the date or date palm, although the term 'date' can have multiple meanings depending on the context. In some cultures, such as in the Philippines,\n"
     ]
    }
   ],
   "source": [
    "queries = [\n",
    "    \"Peter Hobbs founded the company that is based in what town in Manchester?\",\n",
    "    \"Which airport is located in Maine, Sacramento International Airport or Knox County Regional Airport?\",\n",
    "    \"What direction does the river that Austrolebias bellotti are found in flow?\",\n",
    "    \"What event occured at the Red Bull Arena in Salzburg, Austria and Switzerland in 2008?\",\n",
    "    \"Where is the fruit, part of the flowering plant species in the palm family Arecaceae, most popular?\"\n",
    "]\n",
    "\n",
    "# Store raw results for evaluation\n",
    "raw_rag_results = []\n",
    "\n",
    "# 4. 对每个查询执行检索 + 补充答案\n",
    "for i, query in enumerate(queries, 1):\n",
    "  answer, docs = generate_answer(query, None)\n",
    "  print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XV_TP2djvD8T"
   },
   "source": [
    "Feature A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3lYGFHm5vFTn"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6Rcd_AciwCCs"
   },
   "outputs": [],
   "source": [
    "from typing import List, Tuple, Dict, Any\n",
    "\n",
    "class SimpleRetriever:\n",
    "    def __init__(self, rag_system, dataset):\n",
    "        self.rag = rag_system\n",
    "        self.dataset = dataset  # 包含collection字段的数据集\n",
    "\n",
    "    def search(self, query: str, k: int = 10) -> Tuple[List[str], List[Dict[str, Any]]]:\n",
    "        results = self.rag.search(query, k=k)\n",
    "        passages = []\n",
    "        docs_metadata = []\n",
    "\n",
    "        for res in results:\n",
    "            doc_id = res['document_id']\n",
    "            # 从数据集中查找文档文本\n",
    "            doc_text = next(\n",
    "                item['text'] for item in self.dataset['collection']\n",
    "                if item['id'] == doc_id\n",
    "            )\n",
    "            passages.append(doc_text)\n",
    "            docs_metadata.append({\n",
    "                'id': doc_id,\n",
    "                'score': res['score'],\n",
    "                'text': doc_text[:100] + \"...\"  # 存储摘要用于调试\n",
    "            })\n",
    "\n",
    "        return passages, docs_metadata\n",
    "\n",
    "# 初始化示例\n",
    "# 假设已有 rag_system 和 dataset 对象\n",
    "retriever = SimpleRetriever(rag, ds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xSrq_IAV6JAu"
   },
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from transformers import PreTrainedModel, PreTrainedTokenizer\n",
    "\n",
    "@dataclass\n",
    "class GenerationInput:\n",
    "    query: str\n",
    "    retrieved_docs: List[str]\n",
    "    context: str = \"\"  # 多轮对话历史摘要\n",
    "\n",
    "class QwenGenerator:\n",
    "    def __init__(self, model: PreTrainedModel, tokenizer: PreTrainedTokenizer):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def generate(self, input_data: GenerationInput) -> str:\n",
    "        # 构建带上下文的提示词\n",
    "        passages = \"\\n\".join([f\"[{i+1}] {p}\" for i, p in enumerate(input_data.retrieved_docs)])\n",
    "\n",
    "        prompt = f\"\"\"你是一个专业的AI助手，请严格根据以下资料和对话历史回答问题。\n",
    "\n",
    "当前问题：{input_data.query}\n",
    "\n",
    "对话历史：\n",
    "{input_data.context if input_data.context else '无'}\n",
    "\n",
    "相关资料：\n",
    "{passages}\n",
    "\n",
    "回答要求：\n",
    "\n",
    "如果资料不相关，回答\"根据现有资料无法确定\"\n",
    "用中文和英文简洁回答\n",
    "回答：\"\"\"\n",
    "        # 处理长文本截断\n",
    "        inputs = self.tokenizer(\n",
    "            prompt,\n",
    "            return_tensors=\"pt\",\n",
    "            max_length=4096,\n",
    "            truncation=True,\n",
    "            padding=True\n",
    "        ).to(self.model.device)\n",
    "\n",
    "        outputs = self.model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=512,\n",
    "            do_sample=True,\n",
    "            temperature=0.3,  # 降低随机性\n",
    "            top_p=0.85,\n",
    "            pad_token_id=self.tokenizer.eos_token_id\n",
    "        )\n",
    "\n",
    "        response = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        # 提取生成部分（截取\"回答：\"之后的内容）\n",
    "        if \"回答：\" in response:\n",
    "            response = response.split(\"回答：\", 1)[-1].strip()\n",
    "        return response\n",
    "\n",
    "\n",
    "generator = QwenGenerator(model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VgpBYLMVwOkw"
   },
   "outputs": [],
   "source": [
    "class MultiTurnRAGSystem:\n",
    "    def __init__(self, retriever, generator, qwen_model, tokenizer):\n",
    "        self.retriever = retriever\n",
    "        self.generator = generator\n",
    "        self.dialog_manager = MultiTurnDialogManager()\n",
    "        self.query_refiner = QueryRefinementEngine(qwen_model, tokenizer)\n",
    "        self.retrieval_optimizer = MultiTurnRetrievalOptimizer(retriever)\n",
    "\n",
    "    def chat(self, user_query):\n",
    "        \"\"\"处理多轮对话请求\"\"\"\n",
    "\n",
    "        # 1. 获取对话上下文\n",
    "        dialog_context = self.dialog_manager.get_context_summary()\n",
    "\n",
    "        # 2. 查询重构（非首轮时）\n",
    "        if dialog_context:\n",
    "            refined_query = self.query_refiner.refine_query(user_query, dialog_context)\n",
    "            print(\"查询重构（非首轮）\\n：\",refined_query,\"\\nend\")\n",
    "        else:\n",
    "            refined_query = user_query\n",
    "            print(\"原始query\\n：\",refined_query,\"\\nend\")\n",
    "\n",
    "        # 3. 上下文感知检索\n",
    "        retrieved_docs = self.retrieval_optimizer.retrieve_with_context(\n",
    "            refined_query, self.dialog_manager\n",
    "        )\n",
    "        print(\"（上下文感知）检索到的文档是\\n：\",retrieved_docs,\"\\nend\")\n",
    "        # 4. 构建生成输入（包含多轮上下文）\n",
    "        generation_input = GenerationInput(\n",
    "            query=user_query,  # 使用原始查询显示给用户\n",
    "            context=dialog_context,  # 传递对话历史上下文\n",
    "            retrieved_docs=retrieved_docs,\n",
    "        )\n",
    "        print(\"构建生成输入（包含多轮上下文）\\n:\",generation_input,\"\\nend\")\n",
    "        # 5. 调用Qwen2.5生成回答\n",
    "        response = self.generator.generate(generation_input)\n",
    "\n",
    "        # 6. 更新对话状态\n",
    "        self.dialog_manager.add_turn(user_query, response, retrieved_docs)\n",
    "\n",
    "        return {\n",
    "            'response': response,\n",
    "            'refined_query': refined_query,  # 调试信息\n",
    "            'retrieved_docs': retrieved_docs[:3]  # 返回top3文档摘要\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E54H4wnQC_U5"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "class MultiTurnDialogManager:\n",
    "    def __init__(self, max_turns=10, max_context_tokens=4000):\n",
    "        self.dialog_history = []  # 存储对话轮次\n",
    "        self.max_turns = max_turns\n",
    "        self.max_context_tokens = max_context_tokens\n",
    "        self.retrieved_docs_cache = {}  # 文档检索结果缓存\n",
    "\n",
    "    def add_turn(self, query, response, retrieved_docs):\n",
    "        \"\"\"添加一轮对话记录\"\"\"\n",
    "        turn_record = {\n",
    "            'query': query,\n",
    "            'response': response,\n",
    "            'retrieved_docs': retrieved_docs,  # 缓存在此轮次检索到的文档\n",
    "            'timestamp': time.time()\n",
    "        }\n",
    "        self.dialog_history.append(turn_record)\n",
    "\n",
    "        # 维护对话历史长度\n",
    "        if len(self.dialog_history) > self.max_turns:\n",
    "            self.dialog_history.pop(0)\n",
    "\n",
    "    def get_context_summary(self):\n",
    "        \"\"\"生成对话上下文摘要，用于后续检索\"\"\"\n",
    "        if not self.dialog_history:\n",
    "            return \"\"\n",
    "\n",
    "        # 提取最近3轮对话的关键信息\n",
    "        recent_turns = self.dialog_history[-3:]\n",
    "        context_parts = []\n",
    "\n",
    "        for turn in recent_turns:\n",
    "            # 简化为\"用户问：... 系统答：...\"格式\n",
    "            context_parts.append(f\"用户问：{turn['query']}\")\n",
    "            context_parts.append(f\"系统答：{turn['response'][:100]}...\")\n",
    "\n",
    "        return \"\\n\".join(context_parts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nmTUn_7OEt7J"
   },
   "outputs": [],
   "source": [
    "from transformers import PreTrainedModel, PreTrainedTokenizer\n",
    "\n",
    "class QueryRefinementEngine:\n",
    "    def __init__(self, model: PreTrainedModel, tokenizer: PreTrainedTokenizer):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def refine_query(self, current_query, dialog_context):\n",
    "        \"\"\"基于对话上下文重构当前查询\"\"\"\n",
    "        if not dialog_context:\n",
    "            return current_query  # 首轮查询无需重构\n",
    "\n",
    "        prompt_template = \"\"\"\n",
    "基于当前问题和对话历史，请将当前问题重构为一个完整、独立的查询语句。\n",
    "确保解析所有指代（如\"它\"、\"这个\"等），使重构后的查询不依赖对话历史也能被理解。\n",
    "\n",
    "当前问题：{current_query}\n",
    "\n",
    "对话历史：{dialog_context}\n",
    "\n",
    "重构后的完整查询：\n",
    "\"\"\"\n",
    "        prompt = prompt_template.format(\n",
    "            dialog_context=dialog_context,\n",
    "            current_query=current_query\n",
    "        )\n",
    "\n",
    "        # 正确tokenize输入\n",
    "        inputs = self.tokenizer(\n",
    "            prompt,\n",
    "            return_tensors=\"pt\",\n",
    "            max_length=1024,  # 重构查询不需要太长上下文\n",
    "            truncation=True,\n",
    "            padding=True\n",
    "        ).to(self.model.device)\n",
    "\n",
    "        # 生成重构后的查询\n",
    "        outputs = self.model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=50,  # 限制输出长度\n",
    "            do_sample=False,   # 确定性生成\n",
    "            temperature=0.1,   # 降低随机性\n",
    "            pad_token_id=self.tokenizer.eos_token_id\n",
    "        )\n",
    "\n",
    "        # 解码并清理输出\n",
    "        refined_query = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        # 提取生成部分（移除prompt）\n",
    "        if prompt in refined_query:\n",
    "            refined_query = refined_query[len(prompt):].strip()\n",
    "        else:\n",
    "            # 备用方案：按换行分割\n",
    "            refined_query = refined_query.strip().split('\\n')[-1].strip()\n",
    "\n",
    "        # 进一步清理（移除可能的前缀）\n",
    "        if refined_query.startswith(\"重构后的完整查询：\"):\n",
    "            refined_query = refined_query[len(\"重构后的完整查询：\"):].strip()\n",
    "\n",
    "        return refined_query.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q6OIzZeYFDeK"
   },
   "outputs": [],
   "source": [
    "class MultiTurnRetrievalOptimizer:\n",
    "    def __init__(self, base_retriever):\n",
    "        self.retriever = base_retriever\n",
    "        self.doc_seen_tracker = {}  # 跟踪已检索过的文档\n",
    "\n",
    "    def retrieve_with_context(self, refined_query, dialog_manager, k=10):\n",
    "        \"\"\"基于上下文的智能检索\"\"\"\n",
    "\n",
    "        # 执行ColBERT检索\n",
    "        all_docs, metadata = self.retriever.search(refined_query, k=int(k*1.5))  #获取更多候选\n",
    "\n",
    "        # 过滤和重排序策略 略过重排策略\n",
    "        filtered_results = []\n",
    "        for doc in metadata:\n",
    "            filtered_results.append(doc)\n",
    "\n",
    "        # 按新分数排序并返回top-k\n",
    "        filtered_results.sort(key=lambda x: x['score'], reverse=True)\n",
    "        #print(\"filtered_results\",filtered_results,\"end\")\n",
    "\n",
    "        return [i['text'] for i in filtered_results[:k]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 52535,
     "status": "ok",
     "timestamp": 1763952478508,
     "user": {
      "displayName": "Huangao TAN",
      "userId": "10385010319837231346"
     },
     "user_tz": -480
    },
    "id": "BPc0Qt4_B9tC",
    "outputId": "c618f40f-51cd-456a-b56c-f65a76a8f8f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始query\n",
      "： Which airport is located in Maine, Sacramento International Airport or Knox County Regional Airport? \n",
      "end\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/colbert/utils/amp.py:15: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  return torch.cuda.amp.autocast() if self.activated else NullContextManager()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filtered_results [{'id': 'doc-109331', 'score': 23.4375, 'text': 'Knox County Regional Airport. Knox County Regional Airport (IATA: RKD, ICAO: KRKD, FAA LID: RKD) is ...'}, {'id': 'doc-16714', 'score': 21.1875, 'text': 'Penobscot Island Air. Penobscot Island Air is a small regional airline based at Knox County Regional...'}, {'id': 'doc-65306', 'score': 20.109375, 'text': 'Downeast Flight 46. Downeast Airlines Flight 46 was a scheduled airline service in the United States...'}, {'id': 'doc-138769', 'score': 19.328125, 'text': 'Bethel Regional Airport. Bethel Regional Airport (FAA LID: 0B1) is a public airport located two mile...'}, {'id': 'doc-130879', 'score': 18.234375, 'text': 'Owls Head, Maine. Owls Head is a town in Knox County, Maine, United States. The population was 1,580...'}, {'id': 'doc-123664', 'score': 18.0, 'text': 'Matinicus Isle, Maine. Matinicus Isle is an island plantation in Knox County, Maine, United States. ...'}, {'id': 'doc-47096', 'score': 17.875, 'text': 'Sacramento International Airport. Sacramento International Airport (IATA: SMF, ICAO: KSMF, FAA LID: ...'}, {'id': 'doc-121533', 'score': 17.875, 'text': 'Sacramento International Airport. Sacramento International Airport (IATA: SMF, ICAO: KSMF, FAA LID: ...'}, {'id': 'doc-120784', 'score': 17.578125, 'text': 'Sacramento Mather Airport. Sacramento Mather Airport (IATA: MHR, ICAO: KMHR, FAA LID: MHR) , also kn...'}, {'id': 'doc-21065', 'score': 17.375, 'text': 'Vinalhaven, Maine. Vinalhaven is a town located on the larger of the two Fox Islands in Knox County,...'}, {'id': 'doc-11048', 'score': 17.1875, 'text': 'North Haven, Maine. North Haven is a town in Knox County, Maine, United States, in Penobscot Bay. Th...'}, {'id': 'doc-17978', 'score': 17.015625, 'text': 'Lake Cumberland Regional Airport. Lake Cumberland Regional Airport (IATA: SME,\\xa0ICAO: KSME,\\xa0FAA LID: ...'}, {'id': 'doc-8965', 'score': 16.609375, 'text': 'Worcester Regional Airport. Worcester Regional Airport (IATA: ORH, ICAO: KORH, FAA LID: ORH) is a pu...'}, {'id': 'doc-34044', 'score': 16.390625, 'text': 'Greene County Regional Airport. Greene County Regional Airport (FAA LID: 3J7) is a county-owned publ...'}, {'id': 'doc-15718', 'score': 16.3125, 'text': 'Porter County Regional Airport. Porter County Regional Airport (IATA: VPZ,\\xa0ICAO: KVPZ,\\xa0FAA LID: VPZ)...'}] end\n",
      "（上下文感知）检索到的文档是\n",
      "： ['Knox County Regional Airport. Knox County Regional Airport (IATA: RKD, ICAO: KRKD, FAA LID: RKD) is ...', 'Penobscot Island Air. Penobscot Island Air is a small regional airline based at Knox County Regional...', 'Downeast Flight 46. Downeast Airlines Flight 46 was a scheduled airline service in the United States...', 'Bethel Regional Airport. Bethel Regional Airport (FAA LID: 0B1) is a public airport located two mile...', 'Owls Head, Maine. Owls Head is a town in Knox County, Maine, United States. The population was 1,580...', 'Matinicus Isle, Maine. Matinicus Isle is an island plantation in Knox County, Maine, United States. ...', 'Sacramento International Airport. Sacramento International Airport (IATA: SMF, ICAO: KSMF, FAA LID: ...', 'Sacramento International Airport. Sacramento International Airport (IATA: SMF, ICAO: KSMF, FAA LID: ...', 'Sacramento Mather Airport. Sacramento Mather Airport (IATA: MHR, ICAO: KMHR, FAA LID: MHR) , also kn...', 'Vinalhaven, Maine. Vinalhaven is a town located on the larger of the two Fox Islands in Knox County,...'] \n",
      "end\n",
      "构建生成输入（包含多轮上下文）\n",
      ": GenerationInput(query='Which airport is located in Maine, Sacramento International Airport or Knox County Regional Airport?', retrieved_docs=['Knox County Regional Airport. Knox County Regional Airport (IATA: RKD, ICAO: KRKD, FAA LID: RKD) is ...', 'Penobscot Island Air. Penobscot Island Air is a small regional airline based at Knox County Regional...', 'Downeast Flight 46. Downeast Airlines Flight 46 was a scheduled airline service in the United States...', 'Bethel Regional Airport. Bethel Regional Airport (FAA LID: 0B1) is a public airport located two mile...', 'Owls Head, Maine. Owls Head is a town in Knox County, Maine, United States. The population was 1,580...', 'Matinicus Isle, Maine. Matinicus Isle is an island plantation in Knox County, Maine, United States. ...', 'Sacramento International Airport. Sacramento International Airport (IATA: SMF, ICAO: KSMF, FAA LID: ...', 'Sacramento International Airport. Sacramento International Airport (IATA: SMF, ICAO: KSMF, FAA LID: ...', 'Sacramento Mather Airport. Sacramento Mather Airport (IATA: MHR, ICAO: KMHR, FAA LID: MHR) , also kn...', 'Vinalhaven, Maine. Vinalhaven is a town located on the larger of the two Fox Islands in Knox County,...'], context='') \n",
      "end\n",
      "最终返回结果\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'response': 'Knox County Regional Airport是位于美国的机场。它在肯萨斯维尔（Knox County）附近。Vinalhaven是肯萨斯维尔的一个小镇。因此，答案是Knox County Regional Airport。',\n",
       " 'refined_query': 'Which airport is located in Maine, Sacramento International Airport or Knox County Regional Airport?',\n",
       " 'retrieved_docs': ['Knox County Regional Airport. Knox County Regional Airport (IATA: RKD, ICAO: KRKD, FAA LID: RKD) is ...',\n",
       "  'Penobscot Island Air. Penobscot Island Air is a small regional airline based at Knox County Regional...',\n",
       "  'Downeast Flight 46. Downeast Airlines Flight 46 was a scheduled airline service in the United States...']}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "\"\"\"\n",
    "# 1. 加载基础模型（小版本适合查询重构）\n",
    "model_name = \"Qwen/Qwen2.5-0.5B-Instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\"\n",
    ")\"\"\"\n",
    "\n",
    "# 2. 准备检索组件\n",
    "# 假设已有：rag_system (如FAISS), dataset (Hugging Face Dataset)\n",
    "retriever = SimpleRetriever(rag, ds)\n",
    "\n",
    "# 3. 创建生成器\n",
    "generator = QwenGenerator(model, tokenizer)  # 复用同一模型\n",
    "\n",
    "# 4. 创建多轮RAG系统\n",
    "\n",
    "system = MultiTurnRAGSystem(\n",
    "    retriever=retriever,\n",
    "    generator=generator,\n",
    "    qwen_model=model,  # 传入模型实例\n",
    "    tokenizer=tokenizer # 传入tokenizer\n",
    ")\n",
    "\n",
    "# 5. 使用示例\n",
    "response = system.chat(\"Which airport is located in Maine, Sacramento International Airport or Knox County Regional Airport?\")\n",
    "print(\"最终返回结果\")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 160728,
     "status": "ok",
     "timestamp": 1763952639265,
     "user": {
      "displayName": "Huangao TAN",
      "userId": "10385010319837231346"
     },
     "user_tz": -480
    },
    "id": "rMHRcTCZPoX4",
    "outputId": "55971cc9-014e-463c-d916-c7a816a58481"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始query\n",
      "： 什么是机器学习？ \n",
      "end\n",
      "filtered_results [{'id': 'doc-37357', 'score': 17.9375, 'text': 'Nǃxau ǂToma. Nǃxau ǂToma (short: Nǃxau, alternative spelling Gcao Tekene Coma; 16 December 1944 – 5 ...'}, {'id': 'doc-21792', 'score': 17.109375, 'text': 'Tavisupleba. Tavisupleba (Georgian: თავისუფლება , ] ) is the national anthem of Georgia. The anthem,...'}, {'id': 'doc-46341', 'score': 16.828125, 'text': 'Ji (surname 计). Jì is the Mandarin pinyin romanization of the Chinese surname written 计 in simplifie...'}, {'id': 'doc-39798', 'score': 16.765625, 'text': 'Ji (surname 蓟). Jì is the Mandarin pinyin romanization of the Chinese surname written 蓟 in simplifie...'}, {'id': 'doc-45013', 'score': 16.59375, 'text': 'V. T. Bhattathiripad. Vellithuruthi Thazhathu Karutha Patteri Raman Bhattathiripad (1896-1982), popu...'}, {'id': 'doc-49987', 'score': 16.296875, 'text': 'Malé. Malé ( , ] Maldivian: މާލެ ) is the capital and most populous city in the Republic of Maldives...'}, {'id': 'doc-11620', 'score': 16.234375, 'text': 'Evenk Autonomous Banner. Evenk Autonomous Banner (Evenki: ; Ewengki Aimanni Mvvngkeng Isihēr Gosa ; ...'}, {'id': 'doc-24924', 'score': 16.21875, 'text': 'C.L.I.F.. C.L.I.F. (\"Courage, Loyalty, Integrity, Fairness\", or 警徽天职, commonly pronounced as cliff) ...'}, {'id': 'doc-95426', 'score': 16.15625, 'text': 'Run Anthony. Run Antony (Kannada: ರನ್ ಅಂತೋನಿ ) is a 2016 Indian Kannada Action thriller film written...'}, {'id': 'doc-40314', 'score': 16.140625, 'text': 'Gariyoshi. Gariyoshi (গৰীয়সী) is an Assamese language monthly literary magazine published by the Sa...'}, {'id': 'doc-57094', 'score': 16.109375, 'text': 'United National Party. The United National Party, often abbreviated as UNP (Sinhalese: එක්සත් ජාතික ...'}, {'id': 'doc-40617', 'score': 16.078125, 'text': \"Love Yourself: Her. Love Yourself: 承 'Her' is the fifth extended play by South Korean boy group BTS....\"}, {'id': 'doc-82285', 'score': 16.0, 'text': 'Kato (instrument). Kato (Punjabi: ਕਾਟੋ ), also spelled as Kaato or Katto, is one of the traditional ...'}, {'id': 'doc-110360', 'score': 15.8359375, 'text': 'Banzai charge. The banzai charge is considered to be one method of \"gyokusai\" (玉砕 , \"shattered jewel...'}, {'id': 'doc-104303', 'score': 15.8046875, 'text': 'Star of David. The Star of David (✡), known in Hebrew as the Shield of David or Magen David (Hebrew ...'}] end\n",
      "（上下文感知）检索到的文档是\n",
      "： ['Nǃxau ǂToma. Nǃxau ǂToma (short: Nǃxau, alternative spelling Gcao Tekene Coma; 16 December 1944 – 5 ...', 'Tavisupleba. Tavisupleba (Georgian: თავისუფლება , ] ) is the national anthem of Georgia. The anthem,...', 'Ji (surname 计). Jì is the Mandarin pinyin romanization of the Chinese surname written 计 in simplifie...', 'Ji (surname 蓟). Jì is the Mandarin pinyin romanization of the Chinese surname written 蓟 in simplifie...', 'V. T. Bhattathiripad. Vellithuruthi Thazhathu Karutha Patteri Raman Bhattathiripad (1896-1982), popu...', 'Malé. Malé ( , ] Maldivian: މާލެ ) is the capital and most populous city in the Republic of Maldives...', 'Evenk Autonomous Banner. Evenk Autonomous Banner (Evenki: ; Ewengki Aimanni Mvvngkeng Isihēr Gosa ; ...', 'C.L.I.F.. C.L.I.F. (\"Courage, Loyalty, Integrity, Fairness\", or 警徽天职, commonly pronounced as cliff) ...', 'Run Anthony. Run Antony (Kannada: ರನ್ ಅಂತೋನಿ ) is a 2016 Indian Kannada Action thriller film written...', 'Gariyoshi. Gariyoshi (গৰীয়সী) is an Assamese language monthly literary magazine published by the Sa...'] \n",
      "end\n",
      "构建生成输入（包含多轮上下文）\n",
      ": GenerationInput(query='什么是机器学习？', retrieved_docs=['Nǃxau ǂToma. Nǃxau ǂToma (short: Nǃxau, alternative spelling Gcao Tekene Coma; 16 December 1944 – 5 ...', 'Tavisupleba. Tavisupleba (Georgian: თავისუფლება , ] ) is the national anthem of Georgia. The anthem,...', 'Ji (surname 计). Jì is the Mandarin pinyin romanization of the Chinese surname written 计 in simplifie...', 'Ji (surname 蓟). Jì is the Mandarin pinyin romanization of the Chinese surname written 蓟 in simplifie...', 'V. T. Bhattathiripad. Vellithuruthi Thazhathu Karutha Patteri Raman Bhattathiripad (1896-1982), popu...', 'Malé. Malé ( , ] Maldivian: މާލެ ) is the capital and most populous city in the Republic of Maldives...', 'Evenk Autonomous Banner. Evenk Autonomous Banner (Evenki: ; Ewengki Aimanni Mvvngkeng Isihēr Gosa ; ...', 'C.L.I.F.. C.L.I.F. (\"Courage, Loyalty, Integrity, Fairness\", or 警徽天职, commonly pronounced as cliff) ...', 'Run Anthony. Run Antony (Kannada: ರನ್ ಅಂತೋನಿ ) is a 2016 Indian Kannada Action thriller film written...', 'Gariyoshi. Gariyoshi (গৰীয়সী) is an Assamese language monthly literary magazine published by the Sa...'], context='') \n",
      "end\n",
      "Round 1: 机器学习是一种人工智能技术，旨在使计算机系统可以从数据中学习并改进其性能。它通常涉及使用统计方法、模式识别算法和其他计算模型来训练模型以预测或分类新数据点。机器学习在许多领域都有应用，包括图像和语音识...\n",
      "查询重构（非首轮）\n",
      "： 请问机器学习的主要类型是什么？ \n",
      "1. 请提供关于机器学习的主要类型的详细信息。\n",
      "2. 请列出机器学习的主要类型及其应用场景。\n",
      "3. 请解释机器学习的不同类型及其优缺点。\n",
      "4. 请 \n",
      "end\n",
      "filtered_results [{'id': 'doc-37357', 'score': 19.40625, 'text': 'Nǃxau ǂToma. Nǃxau ǂToma (short: Nǃxau, alternative spelling Gcao Tekene Coma; 16 December 1944 – 5 ...'}, {'id': 'doc-57094', 'score': 18.046875, 'text': 'United National Party. The United National Party, often abbreviated as UNP (Sinhalese: එක්සත් ජාතික ...'}, {'id': 'doc-45013', 'score': 17.9375, 'text': 'V. T. Bhattathiripad. Vellithuruthi Thazhathu Karutha Patteri Raman Bhattathiripad (1896-1982), popu...'}, {'id': 'doc-11620', 'score': 17.875, 'text': 'Evenk Autonomous Banner. Evenk Autonomous Banner (Evenki: ; Ewengki Aimanni Mvvngkeng Isihēr Gosa ; ...'}, {'id': 'doc-46341', 'score': 17.78125, 'text': 'Ji (surname 计). Jì is the Mandarin pinyin romanization of the Chinese surname written 计 in simplifie...'}, {'id': 'doc-39798', 'score': 17.734375, 'text': 'Ji (surname 蓟). Jì is the Mandarin pinyin romanization of the Chinese surname written 蓟 in simplifie...'}, {'id': 'doc-49987', 'score': 17.609375, 'text': 'Malé. Malé ( , ] Maldivian: މާލެ ) is the capital and most populous city in the Republic of Maldives...'}, {'id': 'doc-143333', 'score': 17.53125, 'text': 'Ekadashi. \\'Ekādaśī (\"ekāhdaśī\", \"Eleven\") \"Sanskrit: एकादशी , Tamil: ஏகாதசி , Bengali: একাদশী , Telu...'}, {'id': 'doc-26077', 'score': 17.34375, 'text': 'No One Knows (song). \"No One Knows\" is a song by Cantonese pop singer and Hong Kong actress Stephy T...'}, {'id': 'doc-22247', 'score': 17.234375, 'text': 'Anpadh. Anpadh (Hindi: अन्पढ, Urdu: اَنپڑھ, translation: \"illiterate\") is a 1962 Hindi film. The fil...'}, {'id': 'doc-76030', 'score': 17.140625, 'text': 'Chinna Ninna Muddaduve. Chinna Ninna Muddaduve (Kannada: ಚಿನ್ನ ನಿನ್ನ ಮುದ್ದಾಡುವೆ ) is a 1977 Kannada ...'}, {'id': 'doc-40314', 'score': 17.09375, 'text': 'Gariyoshi. Gariyoshi (গৰীয়সী) is an Assamese language monthly literary magazine published by the Sa...'}, {'id': 'doc-32407', 'score': 17.0625, 'text': 'Pradesh. Pradesh refers to a province or territories in various South Asian languages. It is written...'}, {'id': 'doc-82285', 'score': 17.046875, 'text': 'Kato (instrument). Kato (Punjabi: ਕਾਟੋ ), also spelled as Kaato or Katto, is one of the traditional ...'}, {'id': 'doc-110360', 'score': 16.984375, 'text': 'Banzai charge. The banzai charge is considered to be one method of \"gyokusai\" (玉砕 , \"shattered jewel...'}] end\n",
      "（上下文感知）检索到的文档是\n",
      "： ['Nǃxau ǂToma. Nǃxau ǂToma (short: Nǃxau, alternative spelling Gcao Tekene Coma; 16 December 1944 – 5 ...', 'United National Party. The United National Party, often abbreviated as UNP (Sinhalese: එක්සත් ජාතික ...', 'V. T. Bhattathiripad. Vellithuruthi Thazhathu Karutha Patteri Raman Bhattathiripad (1896-1982), popu...', 'Evenk Autonomous Banner. Evenk Autonomous Banner (Evenki: ; Ewengki Aimanni Mvvngkeng Isihēr Gosa ; ...', 'Ji (surname 计). Jì is the Mandarin pinyin romanization of the Chinese surname written 计 in simplifie...', 'Ji (surname 蓟). Jì is the Mandarin pinyin romanization of the Chinese surname written 蓟 in simplifie...', 'Malé. Malé ( , ] Maldivian: މާލެ ) is the capital and most populous city in the Republic of Maldives...', 'Ekadashi. \\'Ekādaśī (\"ekāhdaśī\", \"Eleven\") \"Sanskrit: एकादशी , Tamil: ஏகாதசி , Bengali: একাদশী , Telu...', 'No One Knows (song). \"No One Knows\" is a song by Cantonese pop singer and Hong Kong actress Stephy T...', 'Anpadh. Anpadh (Hindi: अन्पढ, Urdu: اَنپڑھ, translation: \"illiterate\") is a 1962 Hindi film. The fil...'] \n",
      "end\n",
      "构建生成输入（包含多轮上下文）\n",
      ": GenerationInput(query='它有哪些主要类型？', retrieved_docs=['Nǃxau ǂToma. Nǃxau ǂToma (short: Nǃxau, alternative spelling Gcao Tekene Coma; 16 December 1944 – 5 ...', 'United National Party. The United National Party, often abbreviated as UNP (Sinhalese: එක්සත් ජාතික ...', 'V. T. Bhattathiripad. Vellithuruthi Thazhathu Karutha Patteri Raman Bhattathiripad (1896-1982), popu...', 'Evenk Autonomous Banner. Evenk Autonomous Banner (Evenki: ; Ewengki Aimanni Mvvngkeng Isihēr Gosa ; ...', 'Ji (surname 计). Jì is the Mandarin pinyin romanization of the Chinese surname written 计 in simplifie...', 'Ji (surname 蓟). Jì is the Mandarin pinyin romanization of the Chinese surname written 蓟 in simplifie...', 'Malé. Malé ( , ] Maldivian: މާލެ ) is the capital and most populous city in the Republic of Maldives...', 'Ekadashi. \\'Ekādaśī (\"ekāhdaśī\", \"Eleven\") \"Sanskrit: एकादशी , Tamil: ஏகாதசி , Bengali: একাদশী , Telu...', 'No One Knows (song). \"No One Knows\" is a song by Cantonese pop singer and Hong Kong actress Stephy T...', 'Anpadh. Anpadh (Hindi: अन्पढ, Urdu: اَنپڑھ, translation: \"illiterate\") is a 1962 Hindi film. The fil...'], context='用户问：什么是机器学习？\\n系统答：机器学习是一种人工智能技术，旨在使计算机系统可以从数据中学习并改进其性能。它通常涉及使用统计方法、模式识别算法和其他计算模型来训练模型以预测或分类新数据点。机器学习在许多领域都有应用，包括图像和语音识...') \n",
      "end\n",
      "Round 2: 机器学习是一种人工智能技术，旨在使计算机系统从数据中学习并改进其性能。它通常涉及使用统计方法、模式识别算法和其他计算模型来训练模型以预测或分类新数据点。\n",
      "问题：请问机器学习的定义是什么？ \n",
      "答案：机器...\n",
      "查询重构（非首轮）\n",
      "： 请问机器学习的定义是什么？ \n",
      "答案：机器学习是一种人工智能技术，旨在使计算机系统从数据中学习并改进其性能。它通常涉及使用统计方法、模式识别算法和其他计算模型来训练模型以预测或分类新 \n",
      "end\n",
      "filtered_results [{'id': 'doc-11620', 'score': 18.296875, 'text': 'Evenk Autonomous Banner. Evenk Autonomous Banner (Evenki: ; Ewengki Aimanni Mvvngkeng Isihēr Gosa ; ...'}, {'id': 'doc-100411', 'score': 18.25, 'text': \"Mom Thinks I'm Crazy to Marry a Japanese Guy. Mom Thinks I'm Crazy to Marry a Japanese Guy (Mandarin...\"}, {'id': 'doc-39403', 'score': 18.234375, 'text': 'Pan Wenshi. \\u200bPan Wenshi(潘文石) is Peking University professor. His research works on giant panda, whit...'}, {'id': 'doc-82879', 'score': 18.171875, 'text': 'My Voice, My Life. My Voice, My Life 《爭氣》is a feature-length documentary film directed by Oscar-winn...'}, {'id': 'doc-98258', 'score': 18.140625, 'text': 'Fuan no Tane. Fuan no Tane (不安の種 ) is a Japanese horror manga series written and illustrated by Masa...'}, {'id': 'doc-52226', 'score': 18.03125, 'text': 'The Breakup Guru. The Breakup Guru (Chinese: 分手大师) is a 2014 Chinese romantic-comedy-drama film dire...'}, {'id': 'doc-143333', 'score': 17.90625, 'text': 'Ekadashi. \\'Ekādaśī (\"ekāhdaśī\", \"Eleven\") \"Sanskrit: एकादशी , Tamil: ஏகாதசி , Bengali: একাদশী , Telu...'}, {'id': 'doc-39367', 'score': 17.765625, 'text': \"Mystery (2012 film). Mystery (浮城謎事) is a 2012 Chinese drama film directed by Lou Ye. This is Lou Ye'...\"}, {'id': 'doc-99605', 'score': 17.734375, 'text': 'School Ghost Stories. School Ghost Stories (学校の怪談 , Gakkō no Kaidan ) is a 1995 Japanese film direct...'}, {'id': 'doc-63763', 'score': 17.71875, 'text': 'Chan Pui Yin. Chan Pui Yin () is a film producer. She has been with MediaCorp Raintree Pictures (星霖电...'}, {'id': 'doc-26077', 'score': 17.671875, 'text': 'No One Knows (song). \"No One Knows\" is a song by Cantonese pop singer and Hong Kong actress Stephy T...'}, {'id': 'doc-55294', 'score': 17.65625, 'text': 'Human Shadow Etched in Stone. Human Shadow Etched in Stone (Japanese: 人影の石 ) is an exhibition at Hir...'}, {'id': 'doc-104719', 'score': 17.625, 'text': 'The Children of Huang Shi. The Children of Huang Shi (Chinese: 黄石的孩子 ; working title: \"The Bitter Se...'}, {'id': 'doc-13946', 'score': 17.625, 'text': 'The Dancing Girl (short story). \"The Dancing Girl\" (舞姫 , Maihime ) was the first published short sto...'}, {'id': 'doc-40314', 'score': 17.546875, 'text': 'Gariyoshi. Gariyoshi (গৰীয়সী) is an Assamese language monthly literary magazine published by the Sa...'}] end\n",
      "（上下文感知）检索到的文档是\n",
      "： ['Evenk Autonomous Banner. Evenk Autonomous Banner (Evenki: ; Ewengki Aimanni Mvvngkeng Isihēr Gosa ; ...', \"Mom Thinks I'm Crazy to Marry a Japanese Guy. Mom Thinks I'm Crazy to Marry a Japanese Guy (Mandarin...\", 'Pan Wenshi. \\u200bPan Wenshi(潘文石) is Peking University professor. His research works on giant panda, whit...', 'My Voice, My Life. My Voice, My Life 《爭氣》is a feature-length documentary film directed by Oscar-winn...', 'Fuan no Tane. Fuan no Tane (不安の種 ) is a Japanese horror manga series written and illustrated by Masa...', 'The Breakup Guru. The Breakup Guru (Chinese: 分手大师) is a 2014 Chinese romantic-comedy-drama film dire...', 'Ekadashi. \\'Ekādaśī (\"ekāhdaśī\", \"Eleven\") \"Sanskrit: एकादशी , Tamil: ஏகாதசி , Bengali: একাদশী , Telu...', \"Mystery (2012 film). Mystery (浮城謎事) is a 2012 Chinese drama film directed by Lou Ye. This is Lou Ye'...\", 'School Ghost Stories. School Ghost Stories (学校の怪談 , Gakkō no Kaidan ) is a 1995 Japanese film direct...', 'Chan Pui Yin. Chan Pui Yin () is a film producer. She has been with MediaCorp Raintree Pictures (星霖电...'] \n",
      "end\n",
      "构建生成输入（包含多轮上下文）\n",
      ": GenerationInput(query='监督学习和无监督学习有什么区别？', retrieved_docs=['Evenk Autonomous Banner. Evenk Autonomous Banner (Evenki: ; Ewengki Aimanni Mvvngkeng Isihēr Gosa ; ...', \"Mom Thinks I'm Crazy to Marry a Japanese Guy. Mom Thinks I'm Crazy to Marry a Japanese Guy (Mandarin...\", 'Pan Wenshi. \\u200bPan Wenshi(潘文石) is Peking University professor. His research works on giant panda, whit...', 'My Voice, My Life. My Voice, My Life 《爭氣》is a feature-length documentary film directed by Oscar-winn...', 'Fuan no Tane. Fuan no Tane (不安の種 ) is a Japanese horror manga series written and illustrated by Masa...', 'The Breakup Guru. The Breakup Guru (Chinese: 分手大师) is a 2014 Chinese romantic-comedy-drama film dire...', 'Ekadashi. \\'Ekādaśī (\"ekāhdaśī\", \"Eleven\") \"Sanskrit: एकादशी , Tamil: ஏகாதசி , Bengali: একাদশী , Telu...', \"Mystery (2012 film). Mystery (浮城謎事) is a 2012 Chinese drama film directed by Lou Ye. This is Lou Ye'...\", 'School Ghost Stories. School Ghost Stories (学校の怪談 , Gakkō no Kaidan ) is a 1995 Japanese film direct...', 'Chan Pui Yin. Chan Pui Yin () is a film producer. She has been with MediaCorp Raintree Pictures (星霖电...'], context='用户问：什么是机器学习？\\n系统答：机器学习是一种人工智能技术，旨在使计算机系统可以从数据中学习并改进其性能。它通常涉及使用统计方法、模式识别算法和其他计算模型来训练模型以预测或分类新数据点。机器学习在许多领域都有应用，包括图像和语音识...\\n用户问：它有哪些主要类型？\\n系统答：机器学习是一种人工智能技术，旨在使计算机系统从数据中学习并改进其性能。它通常涉及使用统计方法、模式识别算法和其他计算模型来训练模型以预测或分类新数据点。\\n问题：请问机器学习的定义是什么？ \\n答案：机器...') \n",
      "end\n",
      "Round 3: 机器学习是一种人工智能技术，旨在使计算机系统从数据中学习并改进其性能。它通常涉及使用统计方法、模式识别算法和其他计算模型来训练模型以预测或分类新数据点。机器学习在许多领域都有应用，包括图像和语音识别、...\n"
     ]
    }
   ],
   "source": [
    "def test_multiturn_scenario():\n",
    "    \"\"\"测试多轮对话场景\"\"\"\n",
    "    system = MultiTurnRAGSystem(\n",
    "          retriever=retriever,\n",
    "          generator=generator,\n",
    "          qwen_model=model,  # 传入模型实例\n",
    "          tokenizer=tokenizer # 传入tokenizer\n",
    "      )\n",
    "\n",
    "\n",
    "    # 第一轮：基础查询\n",
    "    response1 = system.chat(\"什么是机器学习？\")\n",
    "    print(f\"Round 1: {response1['response'][:100]}...\")\n",
    "\n",
    "    # 第二轮：指代查询\n",
    "    response2 = system.chat(\"它有哪些主要类型？\")\n",
    "    print(f\"Round 2: {response2['response'][:100]}...\")\n",
    "\n",
    "    # 第三轮：深入追问\n",
    "    response3 = system.chat(\"监督学习和无监督学习有什么区别？\")\n",
    "    print(f\"Round 3: {response3['response'][:100]}...\")\n",
    "\n",
    "    # 验证上下文连贯性\n",
    "    assert \"机器学习\" in response2['refined_query']  # 指代应被正确解析\n",
    "    assert len(system.dialog_manager.dialog_history) == 3\n",
    "test_multiturn_scenario()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HxPWwgWLyTTv"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ctKCF_Nnyc32"
   },
   "source": [
    "Feature B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 57300,
     "status": "ok",
     "timestamp": 1764035798681,
     "user": {
      "displayName": "谭黄骜",
      "userId": "15367769941446326953"
     },
     "user_tz": -480
    },
    "id": "_I-VKVb5tOKR",
    "outputId": "07261a58-4051-4918-b792-393291f10889"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 使用真实检索器 ===\n",
      "\n",
      "🚀 开始 ReAct 循环，问题: '并行检索和证据一致性在RAG系统中的作用是什么？'\n",
      "\n",
      "🔁 迭代 1/3\n",
      "📝 计划: 查阅相关文献，了解并行检索和证据一致性的定义及其在RAG系统中的具体应用。 1. 查阅相关文献，理解并行检索和证据一致性的概念；\n",
      "2. 分析并行检索如何提高信息处理效率，以及它对RAG系统的影响；\n",
      "3. 探讨证据一致性在RAG系统中的重要性，包括其对模型训练、推理过程及最终结果质量的作用；\n",
      "4. 研究现有RAG系统的实现方式，并分析它们是如何利用并行检索和证据一致性来提升性能的；\n",
      "5. 根据研究结果，总结并行检索和证据一致性在RAG系统中的主要作用，并提出未来可能的研究方向。\n",
      "\n",
      "🔍 检索查询: ['查阅相关文献，了解并行检索和证据一致性的定义及其在RAG系统中的具体应用。 1. 查阅相关文献，理解并行检索和证据一致性的概念', '分析并行检索如何提高信息处理效率，以及它对RAG系统的影响', '探讨证据一致性在RAG系统中的重要性，包括其对模型训练、推理过程及最终结果质量的作用']\n",
      "📄 找到 9 篇文档\n",
      "🔍 检索查询: 查阅相关文献，了解并行检索和证据一致性的定义及其在RAG系统中的具体应用。 1. 查阅相关文献，理解并行检索和证据一致性的概念 | 分析并行检索如何提高信息处理效率，以及它对RAG系统的影响 | 探讨证据一致性在RAG系统中的重要性，包括其对模型训练、推理过程及最终结果质量的作用\n",
      "\n",
      "🧠 反思输出:\n",
      "--------------------------------------------------\n",
      "你正在执行一个 ReAct（推理-行动）循环。\n",
      "请根据以下信息，判断是否已有足够证据回答原始问题。\n",
      "\n",
      "原始问题：并行检索和证据一致性在RAG系统中的作用是什么？\n",
      "\n",
      "检索计划：查阅相关文献，了解并行检索和证据一致性的定义及其在RAG系统中的具体应用。 1. 查阅相关文献，理解并行检索和证据一致性的概念 | 分析并行检索如何提高信息处理效率，以及它对RAG系统的影响 | 探讨证据一致性在RAG系统中的重要性，包括其对模型训练、推理过程及最终结果质量的作用\n",
      "\n",
      "检索结果：\n",
      "[1] Gaara. Gaara (我愛羅 ) is a fictional character in the \"Naruto\" manga and anime series created by Masashi Kishimoto. Initially introduced as an antagonist, Gaara is a shinobi affiliated with Sunagakure and is the son of Sunagakure's leader, the Fourth Kazekage. He was born as a demon's host as part of his father's intention to have a weapon to restore their village. However, a combination of being ostracized by the Sunagakure villagers, his early inability to control the Tailed Beast, and the notion that his deceased mother called him her curse on the village caused Gaara to become a ruthless killer who believes his own purpose is to kill his enemies. Only after meeting Naruto Uzumaki does Gaara earn a change of perspective, as he eventually becomes Sunagakure's Fifth Kazekage (五代目風影 , Godaime Kazekage ) and gains acceptance by his people. Gaara has appeared in several pieces of \"Naruto\" media, including two of the featured films in the series, the third original video animation, and several video games\n",
      "[2] Cool Silly. Cool Silly () was a Taiwanese-American mainstream pop trio consisting of producer/singer Tone (仲維軍) and rapper/actor Leeway(藍立威), and singer/composer Ray Liu (劉軒蓁). Renowned artist Tone (仲維軍) formed this band after releasing his first album titled \"我的6:57am\" (My 6:57 AM), and recruited two other members to form Cool Silly. In 2011, because the band decided that Ray Liu's musical style is more suitable on her own, Cool Silly became a duo consisting Tony Chung and Leeway Lan. Ray Liu later on pursued music production with her own musical style.\n",
      "[3] Mom Thinks I'm Crazy to Marry a Japanese Guy. Mom Thinks I'm Crazy to Marry a Japanese Guy (Mandarin: 雖然媽媽說我不可以嫁去日本; Japanese: ママは日本へ嫁に行っちゃダメと言うけれど ) is a 2017 romantic-comedy film directed by Akihisa Yachida. Based upon a non-fiction book by Mr. and Mrs. Mogi, the film is a co-production between Japan and Taiwan, and stars Jian Man-shu and Yuta Nakano. The film was theatrically released on May 27, 2017 in Japan and in Taiwan on June 16, 2017.\n",
      "[4] The Breakup Guru. The Breakup Guru (Chinese: 分手大师) is a 2014 Chinese romantic-comedy-drama film directed by Deng Chao and Yu Baimei and also starring Deng Chao and Yang Mi. The film was released on June 27, 2014.\n",
      "[5] Pan Wenshi. ​Pan Wenshi(潘文石) is Peking University professor. His research works on giant panda, white-headed langur and Chinese white dolphin in the last 36 years are internationally recognized contributions. Pan had authored and co-authored 40 – 50 treatises published on various domestic and international journals including National Geographic and Nature and he is renowned for his academic achievements on researching the 3 near-extinct contemporary species. In his book The Natural Refuge of Giant Panda at Qinling (秦嶺大熊猫的自然庇護所) co-authored with postgraduates under his supervision, researchers and other collaborators, Pan put forward for the first time arguments supporting “giant pandas in Qinling can survive living in natural conditions” which was acclaimed by international peers to be “significant contribution to the biological theory of giant panda”. Following that in his book Chance for Continual Survival (繼績生存的機會) Pan commented that “since the cause leading to the near-extinct of giant panda was human error, it must require human to rectify their acts in order giant pandas could have a chance for continual survival”. In the book The White Dolphins of Qinzhou (欽州的白海豚) Prof. Pan and his co-authors unveiled that Chinese white dolphin appeared in Beibu Gulf only from 6000 years ago and that in the Beibu Gulf population is preserved an ancient and rare genotype that is so far never found in populations in other territorial waters. In the book he as well suggested that the social developments of Qinzhou must be planned to optimize a win-win situation between its economy and nature conservation for that is the only way to achieve sustainable development. The Natural History of White-headed Langur (白頭葉猴自然史) is a live record of researches in wilderness. When Prof. Pan went into the Nongguan Mountains he noticed there the sustenance environment was almost totally devastated and that “human was suffering more miserably than the langurs there”. In view of which he suggested “the core issue of nature conservation in Nongguan Mountains is to improve the living conditions of the people there. Only after people’s lives been improved could white-headed langur conservation be anticipated”. 20 years practice of his words has proved his foresight; during the period the white-headed langur population in Nongguan Mountains has increased from the initial of about 100 individuals to about 820 individuals, and the people there have as well gradually improved their livings to well-off standard. <br>\n",
      "[6] List of Kekkaishi episodes. This is a list of episodes for the anime television series Kekkaishi. The series was adapted by Sunrise from the manga \"Kekkaishi\" by Yellow Tanabe. It was directed by Kenji Kodama with character designs by Hirotoshi Takaya and music by Taku Iwasaki. The opening theme for all episodes is \"Sha la la -Ayakashi NIGHT-\" by Saeka Uura. There are four different ending themes: \"Akai Ito\" (赤い糸 , \"Red Thread\") by Koshi Inaba (episodes 1–15, 38, 40, 48, 52), \"Sekaijuu Dokowo Sagashitemo\" (世界中どこを探しても , Sekaijū Doko o Sagashite mo , \"Looking for Another World\") by Aiko Kitahara (episodes 16–23, 39, 44, 51), \"My Mirai\" (マイミライ , Mai Mirai , \"My Future\") by Saeka Uura (episodes 24–30, 41, 46, 49), and \"Kyukei Jikan 10pun\" (休憩時間10分 , Kyūkei Jikan Jippun , \"10 Minute Break\") by Saeka Uura (episodes 31–37, 42-43, 45, 47, 50).\n",
      "[7] Bhairav (raga). Raag Bhairav (Hindi: भैरव/भैरों) (Urdu: ‎ ) (Sindhiبھےرو ) is a Hindustani Classical heptatonic (Sampurna) Raag of Bhairav Thaat. Traditionally it is a morning raga. In modern times, typically in Khyal Gayaki, it is usually performed as the beginning piece in concerts. It is the defining raga of its own Thaat.\n",
      "[8] Asaveri. Asaveri (asāvēri) is a rāgam in Carnatic music (musical scale of South Indian classical music). It is a \"janya\" rāgam (derived scale) from the 8th \"melakarta\" scale \"Hanumatodi\". It is a \"janya\" scale, as it does not have all the seven \"swaras\" (musical notes) in the ascending scale, and has a \"vakra\" (zigzag) descending scale.\n",
      "[9] Dhanyasi. Dhanyasi is a rāgam in Carnatic music (musical scale of South Indian classical music). It is a \"janya\" rāgam (derived scale) from the 8th \"melakarta\" scale \"Hanumatodi\". It is a \"janya\" scale, as it does not have all the seven \"swaras\" (musical notes) in the ascending scale. It is a combination of the pentatonic scale \"Shuddha Dhanyasi\" and the \"sampurna raga\" scale \"Hanumatodi\".\n",
      "\n",
      "请严格按以下格式输出：\n",
      "- 决策：继续检索 / 生成最终答案\n",
      "- 理由：简要说明\n",
      "- （如需继续）新查询：...\n",
      "- （如可回答）最终答案：...\n",
      "\n",
      "你的输出：决策：继续检索 / 生成最终答案  \n",
      "理由：这些文献与原始问题无关，无法提供关于并行检索和证据一致性在RAG系统中的作用的信息。  \n",
      "（如需继续）新查询：查找关于并行检索和证据一致性在RAG系统中的具体应用的相关研究或论文  \n",
      "（如可回答）最终答案：目前没有足够的证据来回答这个问题，因为相关的文献未能提供所需的信息。建议进一步查阅相关领域的学术文章以获取更详细的信息。 \n",
      "\n",
      "总结：由于提供的文献与原始问题无关，因此无法回答该问题。需要更多关于并行检索和证据一致性在RAG系统中的具体应用的研究或论文来回答此问题。\n",
      "--------------------------------------------------\n",
      "\n",
      "=== 最终答案 ===\n",
      "...\n",
      "\n",
      "你的输出：决策：继续检索 / 生成最终答案  \n",
      "理由：这些文献与原始问题无关，无法提供关于并行检索和证据一致性在RAG系统中的作用的信息。  \n",
      "（如需继续）新查询：查找关于并行检索和证据一致性在RAG系统中的具体应用的相关研究或论文  \n",
      "（如可回答）最终答案：目前没有足够的证据来回答这个问题，因为相关的文献未能提供所需的信息。建议进一步查阅相关领域的学术文章以获取更详细的信息。 \n",
      "\n",
      "总结：由于提供的文献与原始问题无关，因此无法回答该问题。需要更多关于并行检索和证据一致性在RAG系统中的具体应用的研究或论文来回答此问题。\n"
     ]
    }
   ],
   "source": [
    "# === 你已有的组件（无需修改）===\n",
    "# class SimpleRetriever 已定义\n",
    "# retriever = SimpleRetriever(rag, ds) 已初始化\n",
    "\n",
    "# === 修正后的 ReAct 核心代码 ===\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Dict, Any, Optional\n",
    "import re\n",
    "\n",
    "########################################\n",
    "# 1. Prompt 模板（保持不变）\n",
    "########################################\n",
    "class PromptTemplates:\n",
    "    def react_reflection_template(self, query: str, retrieved_docs: List[str], plan: str) -> str:\n",
    "        passages = \"\\n\".join([f\"[{i+1}] {p}\" for i, p in enumerate(retrieved_docs)]) if retrieved_docs else \"无\"\n",
    "        return (\n",
    "            \"你正在执行一个 ReAct（推理-行动）循环。\\n\"\n",
    "            \"请根据以下信息，判断是否已有足够证据回答原始问题。\\n\\n\"\n",
    "            f\"原始问题：{query}\\n\\n\"\n",
    "            f\"检索计划：{plan}\\n\\n\"\n",
    "            f\"检索结果：\\n{passages}\\n\\n\"\n",
    "            \"请严格按以下格式输出：\\n\"\n",
    "            \"- 决策：继续检索 / 生成最终答案\\n\"\n",
    "            \"- 理由：简要说明\\n\"\n",
    "            \"- （如需继续）新查询：...\\n\"\n",
    "            \"- （如可回答）最终答案：...\\n\\n\"\n",
    "            \"你的输出：\"\n",
    "        )\n",
    "\n",
    "    def single_round_template(self, query: str, retrieved_docs: List[str], context: str = \"\") -> str:\n",
    "        passages = \"\\n\".join([f\"[{i+1}] {p}\" for i, p in enumerate(retrieved_docs)])\n",
    "        return (\n",
    "            \"你是一个专业的AI助手，请严格根据以下资料和对话历史回答问题。\\n\\n\"\n",
    "            f\"当前问题：{query}\\n\\n\"\n",
    "            \"对话历史：\\n\"\n",
    "            f\"{context if context else '无'}\\n\\n\"\n",
    "            \"相关资料：\\n\"\n",
    "            f\"{passages}\\n\\n\"\n",
    "            \"回答要求：\\n\"\n",
    "            \"如果资料不相关，回答\\\"根据现有资料无法确定\\\"\\n\"\n",
    "            \"用中文和英文简洁回答\\n\"\n",
    "            \"回答：\"\n",
    "        )\n",
    "\n",
    "    def react_plan_template(self, query: str, context: List[str]) -> str:\n",
    "        ctx = \"\\n\".join(context) if context else \"无\"\n",
    "        return (\n",
    "            \"你是一个擅长规划-行动-反思(ReAct)的智能体。\\n\"\n",
    "            \"给定问题与当前上下文，请**仅输出下一步的计划内容**（不要重复指令或问题）。\\n\\n\"\n",
    "            f\"问题：{query}\\n\"\n",
    "            f\"上下文：\\n{ctx}\\n\\n\"\n",
    "            \"计划：\"\n",
    "        )\n",
    "\n",
    "########################################\n",
    "# 2. 数据结构（保持不变）\n",
    "########################################\n",
    "@dataclass\n",
    "class GenerationInput:\n",
    "    query: str\n",
    "    retrieved_docs: List[str]\n",
    "    context: str = \"\"\n",
    "\n",
    "########################################\n",
    "# 3. 基础生成器（关键修正：支持 template_type）\n",
    "########################################\n",
    "class BaseGenerator:\n",
    "    def __init__(self, model_name: str = \"Qwen/Qwen2.5-0.5B-Instruct\"):\n",
    "        self.model_name = model_name\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.model = AutoModelForCausalLM.from_pretrained(\n",
    "            model_name,\n",
    "            torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n",
    "            device_map=\"auto\"\n",
    "        )\n",
    "        self.prompt_templates = PromptTemplates()\n",
    "\n",
    "        self.generation_config = {\n",
    "            \"max_new_tokens\": 512,\n",
    "            \"temperature\": 0.3,\n",
    "            \"top_p\": 0.85,\n",
    "            \"do_sample\": True,\n",
    "            \"pad_token_id\": self.tokenizer.eos_token_id\n",
    "        }\n",
    "\n",
    "    # ✅ 修正：添加 template_type 参数\n",
    "    def generate(self, generation_input: GenerationInput, template_type: str = \"single_round\") -> str:\n",
    "        if template_type == \"single_round\":\n",
    "            prompt = self.prompt_templates.single_round_template(\n",
    "                generation_input.query,\n",
    "                generation_input.retrieved_docs,\n",
    "                generation_input.context\n",
    "            )\n",
    "        elif template_type == \"react_plan\":\n",
    "            prompt = self.prompt_templates.react_plan_template(\n",
    "                generation_input.query,\n",
    "                generation_input.context.split('\\n') if generation_input.context else []\n",
    "            )\n",
    "        elif template_type == \"react_reflection\":\n",
    "            prompt = generation_input.query  # 反思时直接传完整 prompt\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown template_type: {template_type}\")\n",
    "\n",
    "        inputs = self.tokenizer(\n",
    "            prompt,\n",
    "            return_tensors=\"pt\",\n",
    "            max_length=4096,\n",
    "            truncation=True,\n",
    "            padding=True\n",
    "        ).to(self.model.device)\n",
    "\n",
    "        outputs = self.model.generate(**inputs, **self.generation_config)\n",
    "        text = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "        # 只对问答模板做截断\n",
    "        if template_type == \"single_round\" and \"回答：\" in text:\n",
    "            text = text.split(\"回答：\", 1)[-1].strip()\n",
    "\n",
    "        return text.strip()\n",
    "\n",
    "########################################\n",
    "# 4. ReAct Engine（保持你原有的逻辑，只修正调用方式）\n",
    "########################################\n",
    "class ReActEngine:\n",
    "    def __init__(self, generator: BaseGenerator):\n",
    "        self.generator = generator\n",
    "        self.prompt_templates = PromptTemplates()\n",
    "        self.thought_chain: List[str] = []\n",
    "\n",
    "    def _generate_plan(self, state: Dict[str, Any]) -> str:\n",
    "        gi = GenerationInput(\n",
    "            query=state[\"query\"],\n",
    "            retrieved_docs=[],\n",
    "            context=\"\\n\".join(state.get(\"context\", []))\n",
    "        )\n",
    "        raw_output = self.generator.generate(gi, template_type=\"react_plan\")\n",
    "\n",
    "        # ✅ 关键修复：只提取“计划：”之后的内容\n",
    "        if \"计划：\" in raw_output:\n",
    "            plan = raw_output.split(\"计划：\", 1)[-1].strip()\n",
    "        else:\n",
    "            # 如果没有找到分隔符，回退到整个输出（但移除可能的指令前缀）\n",
    "            plan = raw_output\n",
    "            # 移除常见的模板开头\n",
    "            instruction_prefix = \"你是一个擅长规划-行动-反思(ReAct)的智能体。\"\n",
    "            if plan.startswith(instruction_prefix):\n",
    "                plan = plan[len(instruction_prefix):].strip()\n",
    "\n",
    "        return plan\n",
    "\n",
    "    def _execute_action(self, plan: str, state: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        plan_lower = plan.lower()\n",
    "        has_retrieval_intent = (\n",
    "            any(kw in plan_lower for kw in [\"search\", \"retrieval\"]) or\n",
    "            any(kw in plan for kw in [\"检索\", \"查找\", \"查询\"])\n",
    "        )\n",
    "\n",
    "        queries = []\n",
    "        if has_retrieval_intent:\n",
    "            lines = re.split(r'[\\n；;•·\\-–—]+\\s*', plan.strip())\n",
    "            candidate_queries = []\n",
    "\n",
    "            for line in lines:\n",
    "                line = line.strip()\n",
    "                if not line or len(line) < 3:\n",
    "                    continue\n",
    "                cleaned = re.sub(r'^[\\s\\-•\\d\\.\\)\\(（）【】\\[\\]“”‘’\"\\'\\*\\u2022]+\\s*', '', line)\n",
    "                if cleaned.endswith((\".\", \"。\", \"?\", \"？\", \":\", \"：\")):\n",
    "                    continue\n",
    "                candidate_queries.append(cleaned)\n",
    "\n",
    "            if candidate_queries:\n",
    "                queries = candidate_queries[:3]\n",
    "            else:\n",
    "                words = re.findall(r'[a-zA-Z0-9\\u4e00-\\u9fa5]{2,}', plan)\n",
    "                queries = [\" \".join(words[-6:])] if words else [state[\"query\"]]\n",
    "        else:\n",
    "            queries = [state[\"query\"]]\n",
    "\n",
    "        # ✅ 使用你自己的 retriever\n",
    "        all_docs = []\n",
    "        used_queries = []\n",
    "        for q in queries:\n",
    "            docs, _ = state[\"retriever\"].search(q, k=3)  # 你的 SimpleRetriever 返回 (passages, metadata)\n",
    "            all_docs.extend(docs)\n",
    "            used_queries.append(q)\n",
    "\n",
    "        # 去重\n",
    "        unique_docs = list(dict.fromkeys(all_docs))\n",
    "\n",
    "        print(f\"\\n🔍 检索查询: {used_queries}\")\n",
    "        print(f\"📄 找到 {len(unique_docs)} 篇文档\")\n",
    "\n",
    "        return {\n",
    "            \"retrieved_docs\": unique_docs[:10],\n",
    "            \"plan_query\": \" | \".join(used_queries)\n",
    "        }\n",
    "\n",
    "    def _reflect_on_result(self, action_result: Dict[str, Any], state: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        docs = action_result.get(\"retrieved_docs\", [])\n",
    "        plan = action_result.get(\"plan_query\", \"\")\n",
    "\n",
    "        reflection_prompt = self.prompt_templates.react_reflection_template(\n",
    "            query=state[\"query\"],\n",
    "            retrieved_docs=docs,\n",
    "            plan=plan\n",
    "        )\n",
    "\n",
    "        gi = GenerationInput(query=reflection_prompt, retrieved_docs=[], context=\"\")\n",
    "        reflection_output = self.generator.generate(gi, template_type=\"react_reflection\")\n",
    "\n",
    "        print(\"\\n🧠 反思输出:\")\n",
    "        print(\"-\" * 50)\n",
    "        print(reflection_output)\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "        reflection_lower = reflection_output.lower()\n",
    "\n",
    "        if any(kw in reflection_lower for kw in [\"最终答案\", \"final answer\", \"足够\", \"complete\"]):\n",
    "            answer = reflection_output\n",
    "            for marker in [\"最终答案：\", \"final answer:\", \"答案：\", \"answer:\"]:\n",
    "                if marker in reflection_output:\n",
    "                    answer = reflection_output.split(marker, 1)[-1].strip()\n",
    "                    break\n",
    "            return {\"is_final\": True, \"answer\": answer, \"reflection\": reflection_output}\n",
    "\n",
    "        elif any(kw in reflection_lower for kw in [\"继续检索\", \"需进一步\", \"信息不足\", \"缺少\"]):\n",
    "            new_query = state[\"query\"]\n",
    "            for marker in [\"新查询：\", \"new query:\"]:\n",
    "                if marker in reflection_output:\n",
    "                    parts = reflection_output.split(marker, 1)\n",
    "                    if len(parts) > 1:\n",
    "                        new_query = parts[1].split(\"\\n\")[0].strip()\n",
    "                        break\n",
    "            return {\"is_final\": False, \"next_query\": new_query, \"reflection\": reflection_output}\n",
    "\n",
    "        else:\n",
    "            if docs:\n",
    "                gi_answer = GenerationInput(query=state[\"query\"], retrieved_docs=docs, context=\"\")\n",
    "                answer = self.generator.generate(gi_answer)\n",
    "                return {\"is_final\": True, \"answer\": answer, \"reflection\": reflection_output}\n",
    "            else:\n",
    "                return {\"is_final\": False, \"reflection\": reflection_output}\n",
    "\n",
    "    def execute_react_cycle(self, query: str, retriever: Any) -> str:\n",
    "        max_iterations = 3\n",
    "        current_query = query\n",
    "        current_context = []\n",
    "\n",
    "        print(f\"\\n🚀 开始 ReAct 循环，问题: '{query}'\")\n",
    "\n",
    "        for step in range(max_iterations):\n",
    "            print(f\"\\n🔁 迭代 {step+1}/{max_iterations}\")\n",
    "\n",
    "            plan = self._generate_plan({\"query\": current_query, \"context\": current_context, \"retriever\": retriever})\n",
    "            print(f\"📝 计划: {plan}\")\n",
    "\n",
    "            action_result = self._execute_action(plan, {\"query\": current_query, \"retriever\": retriever})\n",
    "            print(f\"🔍 检索查询: {action_result.get('plan_query', '')}\")\n",
    "\n",
    "            reflection = self._reflect_on_result(action_result, {\"query\": current_query, \"retriever\": retriever})\n",
    "\n",
    "            if reflection.get(\"is_final\", False):\n",
    "                return reflection[\"answer\"]\n",
    "\n",
    "            if \"next_query\" in reflection:\n",
    "                current_query = reflection[\"next_query\"]\n",
    "\n",
    "        return \"达到最大迭代次数，未生成最终答案。\"\n",
    "\n",
    "# === 执行你的真实检索器 ===\n",
    "print(\"\\n=== 使用真实检索器 ===\")\n",
    "base_gen = BaseGenerator(model_name=\"Qwen/Qwen2.5-1.5B-Instruct\")\n",
    "# 你已有的初始化：\n",
    "# retriever = SimpleRetriever(rag, ds)\n",
    "\n",
    "react = ReActEngine(generator=base_gen)\n",
    "ans = react.execute_react_cycle(\"并行检索和证据一致性在RAG系统中的作用是什么？\", retriever)\n",
    "print(\"\\n=== 最终答案 ===\")\n",
    "print(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TmKQiyF6ye_l"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNvEay0C/IpF28bWrm2q3+q",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
